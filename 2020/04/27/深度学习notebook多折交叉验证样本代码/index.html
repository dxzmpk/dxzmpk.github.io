<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/%E8%A7%86%E5%8A%9B%E8%A1%A8%20(1).svg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/%E8%A7%86%E5%8A%9B%E8%A1%A8.svg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"dxzmpk.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="深度学习notebook多折交叉验证样本代码这份样本代码基于 @abhishek’s BERT Base Uncased using PyTorch在tweet情感词抽取比赛上的notebook, 如果决定使用代码，请为abhishek投上一个赞成票。 导入需要用到的包12345678910111213141516import osimport torchimport pandas as pdim">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习Notebook多折交叉验证样本代码">
<meta property="og:url" content="https://dxzmpk.github.io/2020/04/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0notebook%E5%A4%9A%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%A0%B7%E6%9C%AC%E4%BB%A3%E7%A0%81/">
<meta property="og:site_name" content="董雄的博客">
<meta property="og:description" content="深度学习notebook多折交叉验证样本代码这份样本代码基于 @abhishek’s BERT Base Uncased using PyTorch在tweet情感词抽取比赛上的notebook, 如果决定使用代码，请为abhishek投上一个赞成票。 导入需要用到的包12345678910111213141516import osimport torchimport pandas as pdim">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-04-27T03:45:20.000Z">
<meta property="article:modified_time" content="2020-04-27T04:17:16.312Z">
<meta property="article:author" content="董雄">
<meta property="article:tag" content="nlp">
<meta property="article:tag" content=" cs">
<meta property="article:tag" content=" hit">
<meta property="article:tag" content=" transformers">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://dxzmpk.github.io/2020/04/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0notebook%E5%A4%9A%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%A0%B7%E6%9C%AC%E4%BB%A3%E7%A0%81/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>深度学习Notebook多折交叉验证样本代码 | 董雄的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">董雄的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">7分nlp,3分计算机基础</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://dxzmpk.github.io/2020/04/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0notebook%E5%A4%9A%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%A0%B7%E6%9C%AC%E4%BB%A3%E7%A0%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="董雄">
      <meta itemprop="description" content="I am a fresh researcher in nlp in Harbin Institute of Technology">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="董雄的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习Notebook多折交叉验证样本代码
        </h1>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-04-27 11:45:20 / 修改时间：12:17:16" itemprop="dateCreated datePublished" datetime="2020-04-27T11:45:20+08:00">2020-04-27</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/04/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0notebook%E5%A4%9A%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%A0%B7%E6%9C%AC%E4%BB%A3%E7%A0%81/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/04/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0notebook%E5%A4%9A%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%A0%B7%E6%9C%AC%E4%BB%A3%E7%A0%81/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="深度学习notebook多折交叉验证样本代码"><a href="#深度学习notebook多折交叉验证样本代码" class="headerlink" title="深度学习notebook多折交叉验证样本代码"></a>深度学习notebook多折交叉验证样本代码</h1><p><strong>这份样本代码基于 @abhishek’s <a href="https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch" target="_blank" rel="noopener">BERT Base Uncased using PyTorch</a>在tweet情感词抽取比赛上的notebook</strong>, 如果决定使用代码，请为abhishek投上一个赞成票。</p>
<h1 id="导入需要用到的包"><a href="#导入需要用到的包" class="headerlink" title="导入需要用到的包"></a>导入需要用到的包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="comment"># tqdm用来记录notebook训练的进度条</span></span><br><span class="line"><span class="keyword">from</span> tqdm.autonotebook <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">import</span> tokenizers</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_linear_schedule_with_warmup</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">config</span>:</span></span><br><span class="line">    MAX_LEN = <span class="number">128</span></span><br><span class="line">    TRAIN_BATCH_SIZE = <span class="number">64</span></span><br><span class="line">    VALID_BATCH_SIZE = <span class="number">16</span></span><br><span class="line">    EPOCHS = <span class="number">6</span></span><br><span class="line">    ROBERTA_PATH = <span class="string">"../input/roberta-base/"</span></span><br><span class="line">    MODEL_PATH = <span class="string">"pytorch_model.bin"</span></span><br><span class="line">    TRAINING_FILE = <span class="string">"../input/tweet-train-folds/train_folds.csv"</span></span><br><span class="line">    TOKENIZER = tokenizers.ByteLevelBPETokenizer(</span><br><span class="line">    vocab_file=<span class="string">f"<span class="subst">&#123;ROBERTA_PATH&#125;</span>/vocab.json"</span>, </span><br><span class="line">    merges_file=<span class="string">f"<span class="subst">&#123;ROBERTA_PATH&#125;</span>/merges.txt"</span>, </span><br><span class="line">    lowercase=<span class="literal">True</span>,</span><br><span class="line">    add_prefix_space=<span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<h1 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_data</span><span class="params">(tweet, selected_text, sentiment, tokenizer, max_len)</span>:</span></span><br><span class="line">    tweet = <span class="string">" "</span> + <span class="string">" "</span>.join(str(tweet).split())</span><br><span class="line">    selected_text = <span class="string">" "</span> + <span class="string">" "</span>.join(str(selected_text).split())</span><br><span class="line"></span><br><span class="line">    len_st = len(selected_text) - <span class="number">1</span></span><br><span class="line">    idx0 = <span class="literal">None</span></span><br><span class="line">    idx1 = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ind <span class="keyword">in</span> (i <span class="keyword">for</span> i, e <span class="keyword">in</span> enumerate(tweet) <span class="keyword">if</span> e == selected_text[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">" "</span> + tweet[ind: ind+len_st] == selected_text:</span><br><span class="line">            idx0 = ind</span><br><span class="line">            idx1 = ind + len_st - <span class="number">1</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    char_targets = [<span class="number">0</span>] * len(tweet)</span><br><span class="line">    <span class="keyword">if</span> idx0 != <span class="literal">None</span> <span class="keyword">and</span> idx1 != <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">for</span> ct <span class="keyword">in</span> range(idx0, idx1 + <span class="number">1</span>):</span><br><span class="line">            char_targets[ct] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    tok_tweet = tokenizer.encode(tweet)</span><br><span class="line">    input_ids_orig = tok_tweet.ids</span><br><span class="line">    tweet_offsets = tok_tweet.offsets</span><br><span class="line">    </span><br><span class="line">    target_idx = []</span><br><span class="line">    <span class="keyword">for</span> j, (offset1, offset2) <span class="keyword">in</span> enumerate(tweet_offsets):</span><br><span class="line">        <span class="keyword">if</span> sum(char_targets[offset1: offset2]) &gt; <span class="number">0</span>:</span><br><span class="line">            target_idx.append(j)</span><br><span class="line">    </span><br><span class="line">    targets_start = target_idx[<span class="number">0</span>]</span><br><span class="line">    targets_end = target_idx[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    sentiment_id = &#123;</span><br><span class="line">        <span class="string">'positive'</span>: <span class="number">1313</span>,</span><br><span class="line">        <span class="string">'negative'</span>: <span class="number">2430</span>,</span><br><span class="line">        <span class="string">'neutral'</span>: <span class="number">7974</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    input_ids = [<span class="number">0</span>] + [sentiment_id[sentiment]] + [<span class="number">2</span>] + [<span class="number">2</span>] + input_ids_orig + [<span class="number">2</span>]</span><br><span class="line">    token_type_ids = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>] + [<span class="number">0</span>] * (len(input_ids_orig) + <span class="number">1</span>)</span><br><span class="line">    mask = [<span class="number">1</span>] * len(token_type_ids)</span><br><span class="line">    tweet_offsets = [(<span class="number">0</span>, <span class="number">0</span>)] * <span class="number">4</span> + tweet_offsets + [(<span class="number">0</span>, <span class="number">0</span>)]</span><br><span class="line">    targets_start += <span class="number">4</span></span><br><span class="line">    targets_end += <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    padding_length = max_len - len(input_ids)</span><br><span class="line">    <span class="keyword">if</span> padding_length &gt; <span class="number">0</span>:</span><br><span class="line">        input_ids = input_ids + ([<span class="number">1</span>] * padding_length)</span><br><span class="line">        mask = mask + ([<span class="number">0</span>] * padding_length)</span><br><span class="line">        token_type_ids = token_type_ids + ([<span class="number">0</span>] * padding_length)</span><br><span class="line">        tweet_offsets = tweet_offsets + ([(<span class="number">0</span>, <span class="number">0</span>)] * padding_length)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">'ids'</span>: input_ids,</span><br><span class="line">        <span class="string">'mask'</span>: mask,</span><br><span class="line">        <span class="string">'token_type_ids'</span>: token_type_ids,</span><br><span class="line">        <span class="string">'targets_start'</span>: targets_start,</span><br><span class="line">        <span class="string">'targets_end'</span>: targets_end,</span><br><span class="line">        <span class="string">'orig_tweet'</span>: tweet,</span><br><span class="line">        <span class="string">'orig_selected'</span>: selected_text,</span><br><span class="line">        <span class="string">'sentiment'</span>: sentiment,</span><br><span class="line">        <span class="string">'offsets'</span>: tweet_offsets</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h1 id="Data-loader"><a href="#Data-loader" class="headerlink" title="Data loader"></a>Data loader</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TweetDataset</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Dataset which stores the tweets and returns them as processed features</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tweet, sentiment, selected_text)</span>:</span></span><br><span class="line">        self.tweet = tweet</span><br><span class="line">        self.sentiment = sentiment</span><br><span class="line">        self.selected_text = selected_text</span><br><span class="line">        self.tokenizer = config.TOKENIZER</span><br><span class="line">        self.max_len = config.MAX_LEN</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.tweet)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, item)</span>:</span></span><br><span class="line">        data = process_data(</span><br><span class="line">            self.tweet[item], </span><br><span class="line">            self.selected_text[item], </span><br><span class="line">            self.sentiment[item],</span><br><span class="line">            self.tokenizer,</span><br><span class="line">            self.max_len</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Return the processed data where the lists are converted to `torch.tensor`s</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">'ids'</span>: torch.tensor(data[<span class="string">"ids"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'mask'</span>: torch.tensor(data[<span class="string">"mask"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'token_type_ids'</span>: torch.tensor(data[<span class="string">"token_type_ids"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'targets_start'</span>: torch.tensor(data[<span class="string">"targets_start"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'targets_end'</span>: torch.tensor(data[<span class="string">"targets_end"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'orig_tweet'</span>: data[<span class="string">"orig_tweet"</span>],</span><br><span class="line">            <span class="string">'orig_selected'</span>: data[<span class="string">"orig_selected"</span>],</span><br><span class="line">            <span class="string">'sentiment'</span>: data[<span class="string">"sentiment"</span>],</span><br><span class="line">            <span class="string">'offsets'</span>: torch.tensor(data[<span class="string">"offsets"</span>], dtype=torch.long)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<h1 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TweetModel</span><span class="params">(transformers.BertPreTrainedModel)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, conf)</span>:</span></span><br><span class="line">        super(TweetModel, self).__init__(conf)</span><br><span class="line">        self.roberta = transformers.RobertaModel.from_pretrained(config.ROBERTA_PATH, config=conf)</span><br><span class="line">        self.drop_out = nn.Dropout(<span class="number">0.1</span>)</span><br><span class="line">        self.l_1 = nn.Linear(<span class="number">768</span> * <span class="number">2</span>, <span class="number">400</span>)</span><br><span class="line">        self.l0 = nn.Linear(<span class="number">400</span>, <span class="number">2</span>)</span><br><span class="line">        torch.nn.init.normal_(self.l0.weight, std=<span class="number">0.02</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, ids, mask, token_type_ids)</span>:</span></span><br><span class="line">        _, _, out = self.roberta(</span><br><span class="line">            ids,</span><br><span class="line">            attention_mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        out = torch.cat((out[<span class="number">-1</span>], out[<span class="number">-2</span>]), dim=<span class="number">-1</span>)</span><br><span class="line">        out = self.drop_out(out)</span><br><span class="line">        logits = self.l_1(out)</span><br><span class="line">        logits = self.l0(logits)</span><br><span class="line"></span><br><span class="line">        start_logits, end_logits = logits.split(<span class="number">1</span>, dim=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        start_logits = start_logits.squeeze(<span class="number">-1</span>)</span><br><span class="line">        end_logits = end_logits.squeeze(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> start_logits, end_logits</span><br></pre></td></tr></table></figure>
<h1 id="自定义损失函数（optional-取决于任务）"><a href="#自定义损失函数（optional-取决于任务）" class="headerlink" title="自定义损失函数（optional,取决于任务）"></a>自定义损失函数（optional,取决于任务）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_fn</span><span class="params">(start_logits, end_logits, start_positions, end_positions)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Return the sum of the cross entropy losses for both the start and end logits</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    loss_fct = nn.CrossEntropyLoss()</span><br><span class="line">    start_loss = loss_fct(start_logits, start_positions)</span><br><span class="line">    end_loss = loss_fct(end_logits, end_positions)</span><br><span class="line">    total_loss = (start_loss + end_loss)</span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br></pre></td></tr></table></figure>
<h1 id="Training-Function"><a href="#Training-Function" class="headerlink" title="Training Function"></a>Training Function</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fn</span><span class="params">(data_loader, model, optimizer, device, scheduler=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Trains the bert model on the twitter data</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Set model to training mode (dropout + sampled batchnorm is activated)</span></span><br><span class="line">    model.train()</span><br><span class="line">    losses = utils.AverageMeter()</span><br><span class="line">    jaccards = utils.AverageMeter()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set tqdm to add loading screen and set the length</span></span><br><span class="line">    tk0 = tqdm(data_loader, total=len(data_loader))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Train the model on each batch</span></span><br><span class="line">    <span class="keyword">for</span> bi, d <span class="keyword">in</span> enumerate(tk0):</span><br><span class="line"></span><br><span class="line">        ids = d[<span class="string">"ids"</span>]</span><br><span class="line">        token_type_ids = d[<span class="string">"token_type_ids"</span>]</span><br><span class="line">        mask = d[<span class="string">"mask"</span>]</span><br><span class="line">        targets_start = d[<span class="string">"targets_start"</span>]</span><br><span class="line">        targets_end = d[<span class="string">"targets_end"</span>]</span><br><span class="line">        sentiment = d[<span class="string">"sentiment"</span>]</span><br><span class="line">        orig_selected = d[<span class="string">"orig_selected"</span>]</span><br><span class="line">        orig_tweet = d[<span class="string">"orig_tweet"</span>]</span><br><span class="line">        targets_start = d[<span class="string">"targets_start"</span>]</span><br><span class="line">        targets_end = d[<span class="string">"targets_end"</span>]</span><br><span class="line">        offsets = d[<span class="string">"offsets"</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Move ids, masks, and targets to gpu while setting as torch.long</span></span><br><span class="line">        ids = ids.to(device, dtype=torch.long)</span><br><span class="line">        token_type_ids = token_type_ids.to(device, dtype=torch.long)</span><br><span class="line">        mask = mask.to(device, dtype=torch.long)</span><br><span class="line">        targets_start = targets_start.to(device, dtype=torch.long)</span><br><span class="line">        targets_end = targets_end.to(device, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Reset gradients</span></span><br><span class="line">        model.zero_grad()</span><br><span class="line">        <span class="comment"># Use ids, masks, and token types as input to the model</span></span><br><span class="line">        <span class="comment"># Predict logits for each of the input tokens for each batch</span></span><br><span class="line">        outputs_start, outputs_end = model(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids,</span><br><span class="line">        ) <span class="comment"># (bs x SL), (bs x SL)</span></span><br><span class="line">        <span class="comment"># Calculate batch loss based on CrossEntropy</span></span><br><span class="line">        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)</span><br><span class="line">        <span class="comment"># Calculate gradients based on loss</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># Adjust weights based on calculated gradients</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># Update scheduler</span></span><br><span class="line">        scheduler.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply softmax to the start and end logits</span></span><br><span class="line">        <span class="comment"># This squeezes each of the logits in a sequence to a value between 0 and 1, while ensuring that they sum to 1</span></span><br><span class="line">        <span class="comment"># This is similar to the characteristics of "probabilities"</span></span><br><span class="line">        outputs_start = torch.softmax(outputs_start, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">        outputs_end = torch.softmax(outputs_end, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculate the jaccard score based on the predictions for this batch</span></span><br><span class="line">        jaccard_scores = []</span><br><span class="line">        <span class="keyword">for</span> px, tweet <span class="keyword">in</span> enumerate(orig_tweet):</span><br><span class="line">            selected_tweet = orig_selected[px]</span><br><span class="line">            tweet_sentiment = sentiment[px]</span><br><span class="line">            jaccard_score, _ = calculate_jaccard_score(</span><br><span class="line">                original_tweet=tweet, <span class="comment"># Full text of the px'th tweet in the batch</span></span><br><span class="line">                target_string=selected_tweet, <span class="comment"># Span containing the specified sentiment for the px'th tweet in the batch</span></span><br><span class="line">                sentiment_val=tweet_sentiment, <span class="comment"># Sentiment of the px'th tweet in the batch</span></span><br><span class="line">                idx_start=np.argmax(outputs_start[px, :]), <span class="comment"># Predicted start index for the px'th tweet in the batch</span></span><br><span class="line">                idx_end=np.argmax(outputs_end[px, :]), <span class="comment"># Predicted end index for the px'th tweet in the batch</span></span><br><span class="line">                offsets=offsets[px] <span class="comment"># Offsets for each of the tokens for the px'th tweet in the batch</span></span><br><span class="line">            )</span><br><span class="line">            jaccard_scores.append(jaccard_score)</span><br><span class="line">        <span class="comment"># Update the jaccard score and loss</span></span><br><span class="line">        <span class="comment"># For details, refer to `AverageMeter` in https://www.kaggle.com/abhishek/utils</span></span><br><span class="line">        jaccards.update(np.mean(jaccard_scores), ids.size(<span class="number">0</span>))</span><br><span class="line">        losses.update(loss.item(), ids.size(<span class="number">0</span>))</span><br><span class="line">        <span class="comment"># Print the average loss and jaccard score at the end of each batch</span></span><br><span class="line">        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)</span><br></pre></td></tr></table></figure>
<h1 id="Evaluation-Functions"><a href="#Evaluation-Functions" class="headerlink" title="Evaluation Functions"></a>Evaluation Functions</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_jaccard_score</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    original_tweet, </span></span></span><br><span class="line"><span class="function"><span class="params">    target_string, </span></span></span><br><span class="line"><span class="function"><span class="params">    sentiment_val, </span></span></span><br><span class="line"><span class="function"><span class="params">    idx_start, </span></span></span><br><span class="line"><span class="function"><span class="params">    idx_end, </span></span></span><br><span class="line"><span class="function"><span class="params">    offsets,</span></span></span><br><span class="line"><span class="function"><span class="params">    verbose=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Calculate the jaccard score from the predicted span and the actual span for a batch of tweets</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># A span's start index has to be greater than or equal to the end index</span></span><br><span class="line">    <span class="comment"># If this doesn't hold, the start index is set to equal the end index (the span is a single token)</span></span><br><span class="line">    <span class="keyword">if</span> idx_end &lt; idx_start:</span><br><span class="line">        idx_end = idx_start</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Combine into a string the tokens that belong to the predicted span</span></span><br><span class="line">    filtered_output  = <span class="string">""</span></span><br><span class="line">    <span class="keyword">for</span> ix <span class="keyword">in</span> range(idx_start, idx_end + <span class="number">1</span>):</span><br><span class="line">        filtered_output += original_tweet[offsets[ix][<span class="number">0</span>]: offsets[ix][<span class="number">1</span>]]</span><br><span class="line">        <span class="comment"># If the token is not the last token in the tweet, and the ending offset of the current token is less</span></span><br><span class="line">        <span class="comment"># than the beginning offset of the following token, add a space.</span></span><br><span class="line">        <span class="comment"># Basically, add a space when the next token (word piece) corresponds to a new word</span></span><br><span class="line">        <span class="keyword">if</span> (ix+<span class="number">1</span>) &lt; len(offsets) <span class="keyword">and</span> offsets[ix][<span class="number">1</span>] &lt; offsets[ix+<span class="number">1</span>][<span class="number">0</span>]:</span><br><span class="line">            filtered_output += <span class="string">" "</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set the predicted output as the original tweet when the tweet's sentiment is "neutral", or the tweet only contains one word</span></span><br><span class="line">    <span class="keyword">if</span> sentiment_val == <span class="string">"neutral"</span> <span class="keyword">or</span> len(original_tweet.split()) &lt; <span class="number">2</span>:</span><br><span class="line">        filtered_output = original_tweet</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the jaccard score between the predicted span, and the actual span</span></span><br><span class="line">    <span class="comment"># The IOU (intersection over union) approach is detailed in the utils module's `jaccard` function:</span></span><br><span class="line">    <span class="comment"># https://www.kaggle.com/abhishek/utils</span></span><br><span class="line">    jac = utils.jaccard(target_string.strip(), filtered_output.strip())</span><br><span class="line">    <span class="keyword">return</span> jac, filtered_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_fn</span><span class="params">(data_loader, model, device)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Evaluation function to predict on the test set</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Set model to evaluation mode</span></span><br><span class="line">    <span class="comment"># I.e., turn off dropout and set batchnorm to use overall mean and variance (from training), rather than batch level mean and variance</span></span><br><span class="line">    <span class="comment"># Reference: https://github.com/pytorch/pytorch/issues/5406</span></span><br><span class="line">    model.eval()</span><br><span class="line">    losses = utils.AverageMeter()</span><br><span class="line">    jaccards = utils.AverageMeter()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Turns off gradient calculations (https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch)</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        tk0 = tqdm(data_loader, total=len(data_loader))</span><br><span class="line">        <span class="comment"># Make predictions and calculate loss / jaccard score for each batch</span></span><br><span class="line">        <span class="keyword">for</span> bi, d <span class="keyword">in</span> enumerate(tk0):</span><br><span class="line">            ids = d[<span class="string">"ids"</span>]</span><br><span class="line">            token_type_ids = d[<span class="string">"token_type_ids"</span>]</span><br><span class="line">            mask = d[<span class="string">"mask"</span>]</span><br><span class="line">            sentiment = d[<span class="string">"sentiment"</span>]</span><br><span class="line">            orig_selected = d[<span class="string">"orig_selected"</span>]</span><br><span class="line">            orig_tweet = d[<span class="string">"orig_tweet"</span>]</span><br><span class="line">            targets_start = d[<span class="string">"targets_start"</span>]</span><br><span class="line">            targets_end = d[<span class="string">"targets_end"</span>]</span><br><span class="line">            offsets = d[<span class="string">"offsets"</span>].numpy()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Move tensors to GPU for faster matrix calculations</span></span><br><span class="line">            ids = ids.to(device, dtype=torch.long)</span><br><span class="line">            token_type_ids = token_type_ids.to(device, dtype=torch.long)</span><br><span class="line">            mask = mask.to(device, dtype=torch.long)</span><br><span class="line">            targets_start = targets_start.to(device, dtype=torch.long)</span><br><span class="line">            targets_end = targets_end.to(device, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Predict logits for start and end indexes</span></span><br><span class="line">            outputs_start, outputs_end = model(</span><br><span class="line">                ids=ids,</span><br><span class="line">                mask=mask,</span><br><span class="line">                token_type_ids=token_type_ids</span><br><span class="line">            )</span><br><span class="line">            <span class="comment"># Calculate loss for the batch</span></span><br><span class="line">            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)</span><br><span class="line">            <span class="comment"># Apply softmax to the predicted logits for the start and end indexes</span></span><br><span class="line">            <span class="comment"># This converts the "logits" to "probability-like" scores</span></span><br><span class="line">            outputs_start = torch.softmax(outputs_start, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">            outputs_end = torch.softmax(outputs_end, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">            <span class="comment"># Calculate jaccard scores for each tweet in the batch</span></span><br><span class="line">            jaccard_scores = []</span><br><span class="line">            <span class="keyword">for</span> px, tweet <span class="keyword">in</span> enumerate(orig_tweet):</span><br><span class="line">                selected_tweet = orig_selected[px]</span><br><span class="line">                tweet_sentiment = sentiment[px]</span><br><span class="line">                jaccard_score, _ = calculate_jaccard_score(</span><br><span class="line">                    original_tweet=tweet,</span><br><span class="line">                    target_string=selected_tweet,</span><br><span class="line">                    sentiment_val=tweet_sentiment,</span><br><span class="line">                    idx_start=np.argmax(outputs_start[px, :]),</span><br><span class="line">                    idx_end=np.argmax(outputs_end[px, :]),</span><br><span class="line">                    offsets=offsets[px]</span><br><span class="line">                )</span><br><span class="line">                jaccard_scores.append(jaccard_score)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Update running jaccard score and loss</span></span><br><span class="line">            jaccards.update(np.mean(jaccard_scores), ids.size(<span class="number">0</span>))</span><br><span class="line">            losses.update(loss.item(), ids.size(<span class="number">0</span>))</span><br><span class="line">            <span class="comment"># Print the running average loss and jaccard score</span></span><br><span class="line">            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">f"Jaccard = <span class="subst">&#123;jaccards.avg&#125;</span>"</span>)</span><br><span class="line">    <span class="keyword">return</span> jaccards.avg</span><br></pre></td></tr></table></figure>
<h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(fold)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Train model for a speciied fold</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Read training csv</span></span><br><span class="line">    dfx = pd.read_csv(config.TRAINING_FILE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set train validation set split</span></span><br><span class="line">    df_train = dfx[dfx.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = dfx[dfx.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Instantiate TweetDataset with training data</span></span><br><span class="line">    train_dataset = TweetDataset(</span><br><span class="line">        tweet=df_train.text.values,</span><br><span class="line">        sentiment=df_train.sentiment.values,</span><br><span class="line">        selected_text=df_train.selected_text.values</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Instantiate DataLoader with `train_dataset`</span></span><br><span class="line">    <span class="comment"># This is a generator that yields the dataset in batches</span></span><br><span class="line">    train_data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        train_dataset,</span><br><span class="line">        batch_size=config.TRAIN_BATCH_SIZE,</span><br><span class="line">        num_workers=<span class="number">4</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Instantiate TweetDataset with validation data</span></span><br><span class="line">    valid_dataset = TweetDataset(</span><br><span class="line">        tweet=df_valid.text.values,</span><br><span class="line">        sentiment=df_valid.sentiment.values,</span><br><span class="line">        selected_text=df_valid.selected_text.values</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Instantiate DataLoader with `valid_dataset`</span></span><br><span class="line">    valid_data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        valid_dataset,</span><br><span class="line">        batch_size=config.VALID_BATCH_SIZE,</span><br><span class="line">        num_workers=<span class="number">2</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set device as `cuda` (GPU)</span></span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">    <span class="comment"># Load pretrained BERT (bert-base-uncased)</span></span><br><span class="line">    model_config = transformers.RobertaConfig.from_pretrained(config.ROBERTA_PATH)</span><br><span class="line">    <span class="comment"># Output hidden states</span></span><br><span class="line">    <span class="comment"># This is important to set since we want to concatenate the hidden states from the last 2 BERT layers</span></span><br><span class="line">    model_config.output_hidden_states = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># Instantiate our model with `model_config`</span></span><br><span class="line">    model = TweetModel(conf=model_config)</span><br><span class="line">    <span class="comment"># Move the model to the GPU</span></span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the number of training steps</span></span><br><span class="line">    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)</span><br><span class="line">    <span class="comment"># Get the list of named parameters</span></span><br><span class="line">    param_optimizer = list(model.named_parameters())</span><br><span class="line">    <span class="comment"># Specify parameters where weight decay shouldn't be applied</span></span><br><span class="line">    no_decay = [<span class="string">"bias"</span>, <span class="string">"LayerNorm.bias"</span>, <span class="string">"LayerNorm.weight"</span>]</span><br><span class="line">    <span class="comment"># Define two sets of parameters: those with weight decay, and those without</span></span><br><span class="line">    optimizer_parameters = [</span><br><span class="line">        &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> param_optimizer <span class="keyword">if</span> <span class="keyword">not</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.001</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> param_optimizer <span class="keyword">if</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.0</span>&#125;,</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># Instantiate AdamW optimizer with our two sets of parameters, and a learning rate of 3e-5</span></span><br><span class="line">    optimizer = AdamW(optimizer_parameters, lr=<span class="number">3e-5</span>)</span><br><span class="line">    <span class="comment"># Create a scheduler to set the learning rate at each training step</span></span><br><span class="line">    <span class="comment"># "Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period." (https://pytorch.org/docs/stable/optim.html)</span></span><br><span class="line">    <span class="comment"># Since num_warmup_steps = 0, the learning rate starts at 3e-5, and then linearly decreases at each training step</span></span><br><span class="line">    scheduler = get_linear_schedule_with_warmup(</span><br><span class="line">        optimizer, </span><br><span class="line">        num_warmup_steps=<span class="number">0</span>, </span><br><span class="line">        num_training_steps=num_train_steps</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Apply early stopping with patience of 2</span></span><br><span class="line">    <span class="comment"># This means to stop training new epochs when 2 rounds have passed without any improvement</span></span><br><span class="line">    es = utils.EarlyStopping(patience=<span class="number">2</span>, mode=<span class="string">"max"</span>)</span><br><span class="line">    print(<span class="string">f"Training is Starting for fold=<span class="subst">&#123;fold&#125;</span>"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># I'm training only for 3 epochs even though I specified 5!!!</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)</span><br><span class="line">        jaccard = eval_fn(valid_data_loader, model, device)</span><br><span class="line">        print(<span class="string">f"Jaccard Score = <span class="subst">&#123;jaccard&#125;</span>"</span>)</span><br><span class="line">        es(jaccard, model, model_path=<span class="string">f"model_<span class="subst">&#123;fold&#125;</span>.bin"</span>)</span><br><span class="line">        <span class="keyword">if</span> es.early_stop:</span><br><span class="line">            print(<span class="string">"Early stopping"</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Do-the-evaluation-on-test-data"><a href="#Do-the-evaluation-on-test-data" class="headerlink" title="Do the evaluation on test data"></a>Do the evaluation on test data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_test = pd.read_csv(<span class="string">"../input/tweet-sentiment-extraction/test.csv"</span>)</span><br><span class="line">df_test.loc[:, <span class="string">"selected_text"</span>] = df_test.text.values</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_test</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>textID</th>
      <th>text</th>
      <th>sentiment</th>
      <th>selected_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>f87dea47db</td>
      <td>Last session of the day  http://twitpic.com/67ezh</td>
      <td>neutral</td>
      <td>Last session of the day  http://twitpic.com/67ezh</td>
    </tr>
    <tr>
      <th>1</th>
      <td>96d74cb729</td>
      <td>Shanghai is also really exciting (precisely -...</td>
      <td>positive</td>
      <td>Shanghai is also really exciting (precisely -...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>eee518ae67</td>
      <td>Recession hit Veronique Branquinho, she has to...</td>
      <td>negative</td>
      <td>Recession hit Veronique Branquinho, she has to...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>01082688c6</td>
      <td>happy bday!</td>
      <td>positive</td>
      <td>happy bday!</td>
    </tr>
    <tr>
      <th>4</th>
      <td>33987a8ee5</td>
      <td>http://twitpic.com/4w75p - I like it!!</td>
      <td>positive</td>
      <td>http://twitpic.com/4w75p - I like it!!</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3529</th>
      <td>e5f0e6ef4b</td>
      <td>its at 3 am, im very tired but i can`t sleep  ...</td>
      <td>negative</td>
      <td>its at 3 am, im very tired but i can`t sleep  ...</td>
    </tr>
    <tr>
      <th>3530</th>
      <td>416863ce47</td>
      <td>All alone in this old house again.  Thanks for...</td>
      <td>positive</td>
      <td>All alone in this old house again.  Thanks for...</td>
    </tr>
    <tr>
      <th>3531</th>
      <td>6332da480c</td>
      <td>I know what you mean. My little dog is sinkin...</td>
      <td>negative</td>
      <td>I know what you mean. My little dog is sinkin...</td>
    </tr>
    <tr>
      <th>3532</th>
      <td>df1baec676</td>
      <td>_sutra what is your next youtube video gonna b...</td>
      <td>positive</td>
      <td>_sutra what is your next youtube video gonna b...</td>
    </tr>
    <tr>
      <th>3533</th>
      <td>469e15c5a8</td>
      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>
      <td>positive</td>
      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>
    </tr>
  </tbody>
</table>
<p>3534 rows × 4 columns</p>

</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">model_config = transformers.RobertaConfig.from_pretrained(config.ROBERTA_PATH)</span><br><span class="line">model_config.output_hidden_states = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load each of the five trained models and move to GPU</span></span><br><span class="line">model1 = TweetModel(conf=model_config)</span><br><span class="line">model1.to(device)</span><br><span class="line">model1.load_state_dict(torch.load(<span class="string">"model_0.bin"</span>))</span><br><span class="line">model1.eval()</span><br><span class="line"></span><br><span class="line">model2 = TweetModel(conf=model_config)</span><br><span class="line">model2.to(device)</span><br><span class="line">model2.load_state_dict(torch.load(<span class="string">"model_1.bin"</span>))</span><br><span class="line">model2.eval()</span><br><span class="line"></span><br><span class="line">model3 = TweetModel(conf=model_config)</span><br><span class="line">model3.to(device)</span><br><span class="line">model3.load_state_dict(torch.load(<span class="string">"model_2.bin"</span>))</span><br><span class="line">model3.eval()</span><br><span class="line"></span><br><span class="line">model4 = TweetModel(conf=model_config)</span><br><span class="line">model4.to(device)</span><br><span class="line">model4.load_state_dict(torch.load(<span class="string">"model_3.bin"</span>))</span><br><span class="line">model4.eval()</span><br><span class="line"></span><br><span class="line">model5 = TweetModel(conf=model_config)</span><br><span class="line">model5.to(device)</span><br><span class="line">model5.load_state_dict(torch.load(<span class="string">"model_4.bin"</span>))</span><br><span class="line">model5.eval()</span><br></pre></td></tr></table></figure>
<pre><code>TweetModel(
  (roberta): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (drop_out): Dropout(p=0.1, inplace=False)
  (l_1): Linear(in_features=1536, out_features=400, bias=True)
  (l0): Linear(in_features=400, out_features=2, bias=True)
)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">final_output = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate TweetDataset with the test data</span></span><br><span class="line">test_dataset = TweetDataset(</span><br><span class="line">        tweet=df_test.text.values,</span><br><span class="line">        sentiment=df_test.sentiment.values,</span><br><span class="line">        selected_text=df_test.selected_text.values</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate DataLoader with `test_dataset`</span></span><br><span class="line">data_loader = torch.utils.data.DataLoader(</span><br><span class="line">    test_dataset,</span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    batch_size=config.VALID_BATCH_SIZE,</span><br><span class="line">    num_workers=<span class="number">1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn of gradient calculations</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    tk0 = tqdm(data_loader, total=len(data_loader))</span><br><span class="line">    <span class="comment"># Predict the span containing the sentiment for each batch</span></span><br><span class="line">    <span class="keyword">for</span> bi, d <span class="keyword">in</span> enumerate(tk0):</span><br><span class="line">        ids = d[<span class="string">"ids"</span>]</span><br><span class="line">        token_type_ids = d[<span class="string">"token_type_ids"</span>]</span><br><span class="line">        mask = d[<span class="string">"mask"</span>]</span><br><span class="line">        sentiment = d[<span class="string">"sentiment"</span>]</span><br><span class="line">        orig_selected = d[<span class="string">"orig_selected"</span>]</span><br><span class="line">        orig_tweet = d[<span class="string">"orig_tweet"</span>]</span><br><span class="line">        targets_start = d[<span class="string">"targets_start"</span>]</span><br><span class="line">        targets_end = d[<span class="string">"targets_end"</span>]</span><br><span class="line">        offsets = d[<span class="string">"offsets"</span>].numpy()</span><br><span class="line"></span><br><span class="line">        ids = ids.to(device, dtype=torch.long)</span><br><span class="line">        token_type_ids = token_type_ids.to(device, dtype=torch.long)</span><br><span class="line">        mask = mask.to(device, dtype=torch.long)</span><br><span class="line">        targets_start = targets_start.to(device, dtype=torch.long)</span><br><span class="line">        targets_end = targets_end.to(device, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Predict start and end logits for each of the five models</span></span><br><span class="line">        outputs_start1, outputs_end1 = model1(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        outputs_start2, outputs_end2 = model2(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        outputs_start3, outputs_end3 = model3(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        outputs_start4, outputs_end4 = model4(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        outputs_start5, outputs_end5 = model5(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get the average start and end logits across the five models and use these as predictions</span></span><br><span class="line">        <span class="comment"># This is a form of "ensembling"</span></span><br><span class="line">        outputs_start = (</span><br><span class="line">            outputs_start1 </span><br><span class="line">            + outputs_start2 </span><br><span class="line">            + outputs_start3 </span><br><span class="line">            + outputs_start4 </span><br><span class="line">            + outputs_start5</span><br><span class="line">        ) / <span class="number">5</span></span><br><span class="line">        outputs_end = (</span><br><span class="line">            outputs_end1 </span><br><span class="line">            + outputs_end2 </span><br><span class="line">            + outputs_end3 </span><br><span class="line">            + outputs_end4 </span><br><span class="line">            + outputs_end5</span><br><span class="line">        ) / <span class="number">5</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply softmax to the predicted start and end logits</span></span><br><span class="line">        outputs_start = torch.softmax(outputs_start, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">        outputs_end = torch.softmax(outputs_end, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Convert the start and end scores to actual predicted spans (in string form)</span></span><br><span class="line">        <span class="keyword">for</span> px, tweet <span class="keyword">in</span> enumerate(orig_tweet):</span><br><span class="line">            selected_tweet = orig_selected[px]</span><br><span class="line">            tweet_sentiment = sentiment[px]</span><br><span class="line">            _, output_sentence = calculate_jaccard_score(</span><br><span class="line">                original_tweet=tweet,</span><br><span class="line">                target_string=selected_tweet,</span><br><span class="line">                sentiment_val=tweet_sentiment,</span><br><span class="line">                idx_start=np.argmax(outputs_start[px, :]),</span><br><span class="line">                idx_end=np.argmax(outputs_end[px, :]),</span><br><span class="line">                offsets=offsets[px]</span><br><span class="line">            )</span><br><span class="line">            final_output.append(output_sentence)</span><br></pre></td></tr></table></figure>
<pre><code>HBox(children=(FloatProgress(value=0.0, max=221.0), HTML(value=&#39;&#39;)))
</code></pre><p>​<br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># post-process trick:</span></span><br><span class="line"><span class="comment"># Note: This trick comes from: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/140942</span></span><br><span class="line"><span class="comment"># When the LB resets, this trick won't help</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post_process</span><span class="params">(selected)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">" "</span>.join(set(selected.lower().split()))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sample = pd.read_csv(<span class="string">"../input/tweet-sentiment-extraction/sample_submission.csv"</span>)</span><br><span class="line">sample.loc[:, <span class="string">'selected_text'</span>] = final_output</span><br><span class="line">sample.selected_text = sample.selected_text.map(post_process)</span><br><span class="line">sample.to_csv(<span class="string">"submission.csv"</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>textID</th>
      <th>selected_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>f87dea47db</td>
      <td>http://twitpic.com/67ezh the of day session last</td>
    </tr>
    <tr>
      <th>1</th>
      <td>96d74cb729</td>
      <td>exciting</td>
    </tr>
    <tr>
      <th>2</th>
      <td>eee518ae67</td>
      <td>such shame! a</td>
    </tr>
    <tr>
      <th>3</th>
      <td>01082688c6</td>
      <td>happy bday!</td>
    </tr>
    <tr>
      <th>4</th>
      <td>33987a8ee5</td>
      <td>i like</td>
    </tr>
  </tbody>
</table>

</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line">source_DF = inspect.getsource(utils)</span><br><span class="line">print(source_DF)</span><br></pre></td></tr></table></figure>
<pre><code>import numpy as np
import torch
</code></pre><p>​    </p>
<pre><code>class AverageMeter:
    &quot;&quot;&quot;
    Computes and stores the average and current value
    &quot;&quot;&quot;
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count
</code></pre><p>​    </p>
<pre><code>class EarlyStopping:
    def __init__(self, patience=7, mode=&quot;max&quot;, delta=0.001):
        self.patience = patience
        self.counter = 0
        self.mode = mode
        self.best_score = None
        self.early_stop = False
        self.delta = delta
        if self.mode == &quot;min&quot;:
            self.val_score = np.Inf
        else:
            self.val_score = -np.Inf

    def __call__(self, epoch_score, model, model_path):

        if self.mode == &quot;min&quot;:
            score = -1.0 * epoch_score
        else:
            score = np.copy(epoch_score)

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(epoch_score, model, model_path)
        elif score &lt; self.best_score + self.delta:
            self.counter += 1
            print(&#39;EarlyStopping counter: {} out of {}&#39;.format(self.counter, self.patience))
            if self.counter &gt;= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(epoch_score, model, model_path)
            self.counter = 0

    def save_checkpoint(self, epoch_score, model, model_path):
        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:
            print(&#39;Validation score improved ({} --&gt; {}). Saving model!&#39;.format(self.val_score, epoch_score))
            torch.save(model.state_dict(), model_path)
        self.val_score = epoch_score
</code></pre><p>​    </p>
<pre><code>def jaccard(str1, str2): 
    a = set(str1.lower().split()) 
    b = set(str2.lower().split())
    c = a.intersection(b)
    return float(len(c)) / (len(a) + len(b) - len(c))
</code></pre><p>​    </p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/04/24/%E6%99%AE%E9%80%9A%E5%AD%A6%E7%94%9F%EF%BC%8C%E5%A6%82%E4%BD%95%E7%94%A8Colab%E8%B7%91%E8%B5%B7%E6%9D%A5BERT%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%9F/" rel="prev" title="普通学生，如何用Colab跑起来BERT系列模型？">
      <i class="fa fa-chevron-left"></i> 普通学生，如何用Colab跑起来BERT系列模型？
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/29/Bert%E7%B3%BB%E5%88%97%E4%BC%B4%E7%94%9F%E7%9A%84%E6%96%B0%E5%88%86%E8%AF%8D%E5%99%A8/" rel="next" title="Bert系列伴生的新分词器">
      Bert系列伴生的新分词器 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#深度学习notebook多折交叉验证样本代码"><span class="nav-number">1.</span> <span class="nav-text">深度学习notebook多折交叉验证样本代码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#导入需要用到的包"><span class="nav-number">2.</span> <span class="nav-text">导入需要用到的包</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Data-Processing"><span class="nav-number">3.</span> <span class="nav-text">Data Processing</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Data-loader"><span class="nav-number">4.</span> <span class="nav-text">Data loader</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型定义"><span class="nav-number">5.</span> <span class="nav-text">模型定义</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#自定义损失函数（optional-取决于任务）"><span class="nav-number">6.</span> <span class="nav-text">自定义损失函数（optional,取决于任务）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Training-Function"><span class="nav-number">7.</span> <span class="nav-text">Training Function</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Evaluation-Functions"><span class="nav-number">8.</span> <span class="nav-text">Evaluation Functions</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Training"><span class="nav-number">9.</span> <span class="nav-text">Training</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Do-the-evaluation-on-test-data"><span class="nav-number">10.</span> <span class="nav-text">Do the evaluation on test data</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">董雄</p>
  <div class="site-description" itemprop="description">I am a fresh researcher in nlp in Harbin Institute of Technology</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">董雄</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        


  <div style="display: none;">
    <script src="//s95.cnzz.com/z_stat.php?id=1278837449&web_id=1278837449"></script>
  </div>






      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 't8n8RTilca5Gm0vKToaMrjRU-gzGzoHsz',
      appKey     : 'x4Jty8MrDpczjPANtbbGhwXX',
      placeholder: "请留下一点痕迹吧, 评论将永远留存",
      avatar     : 'robohash',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
