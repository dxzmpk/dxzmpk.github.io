<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/%E8%A7%86%E5%8A%9B%E8%A1%A8%20(1).svg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/%E8%A7%86%E5%8A%9B%E8%A1%A8.svg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"dxzmpk.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Learning in Harbin Institute of Technology">
<meta property="og:type" content="website">
<meta property="og:title" content="è‘£é›„å†™å­—çš„åœ°æ–¹">
<meta property="og:url" content="https://dxzmpk.github.io/page/2/">
<meta property="og:site_name" content="è‘£é›„å†™å­—çš„åœ°æ–¹">
<meta property="og:description" content="Learning in Harbin Institute of Technology">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="è‘£é›„">
<meta property="article:tag" content="nlp">
<meta property="article:tag" content=" cs">
<meta property="article:tag" content=" hit">
<meta property="article:tag" content=" transformers">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://dxzmpk.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>è‘£é›„å†™å­—çš„åœ°æ–¹</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="åˆ‡æ¢å¯¼èˆªæ ">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">è‘£é›„å†™å­—çš„åœ°æ–¹</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">endless hard working</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>é¦–é¡µ</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>å…³äº</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>æ ‡ç­¾</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>åˆ†ç±»</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>å½’æ¡£</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://dxzmpk.github.io/2020/05/08/%E4%B8%89%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%BC%80%E5%90%AF%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%80%9A%E7%9F%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="è‘£é›„">
      <meta itemprop="description" content="Learning in Harbin Institute of Technology">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="è‘£é›„å†™å­—çš„åœ°æ–¹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/08/%E4%B8%89%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%BC%80%E5%90%AF%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%80%9A%E7%9F%A5/" class="post-title-link" itemprop="url">ä¸‰è¡Œä»£ç å¼€å¯æ¨¡å‹è®­ç»ƒé€šçŸ¥</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">å‘è¡¨äº</span>

              <time title="åˆ›å»ºæ—¶é—´ï¼š2020-05-08 12:12:05" itemprop="dateCreated datePublished" datetime="2020-05-08T12:12:05+08:00">2020-05-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-14 21:15:05" itemprop="dateModified" datetime="2020-05-14T21:15:05+08:00">2020-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
            </span>

          
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h2><p>å¦‚æœä½ ç»å¸¸åœ¨å¤§é‡æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹çš„è¯ï¼Œé‚£ä¹ˆè¿™æ ·ä¸€ä¸ªå·¥å…·è‚¯å®šå¾ˆåˆä½ çš„èƒƒå£ã€‚è¿™ä¸ªé¡¹ç›®å«åš<a href="https://github.com/huggingface/knockknock" target="_blank" rel="noopener">knockknock</a>ï¼Œå®ƒçš„åŠŸèƒ½åªæœ‰ä¸€ä¸ªï¼šé€šçŸ¥ä½ è®­ç»ƒç»“æŸäº†ï¼Œå¹¶ä¸”é™„å¸¦è®­ç»ƒçš„ç»“æœã€‚</p>
<p>å½“å‰æ”¯æŒé‚®ä»¶ã€çŸ­ä¿¡ã€å¾®ä¿¡ç¾¤ã€é’‰é’‰ç¾¤ç­‰é€šçŸ¥æ–¹å¼ï¼Œåªéœ€è¦ä¸‰è¡Œä»£ç ï¼Œå°±èƒ½å®ç°åŠŸèƒ½ã€‚</p>
<h2 id="æ•ˆæœå±•ç¤º"><a href="#æ•ˆæœå±•ç¤º" class="headerlink" title="æ•ˆæœå±•ç¤º"></a>æ•ˆæœå±•ç¤º</h2><p>ä¸ºäº†è®©ä½ æœ‰çœ‹ä¸‹å»çš„åŠ¨åŠ›ï¼Œå…ˆå±•ç¤ºä¸€ä¸‹æœ€ç»ˆçš„æˆæœ(é’‰é’‰)ï¼š</p>
<p><img src="/images/%E4%B8%89%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%BC%80%E5%90%AF%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%80%9A%E7%9F%A5/share.jpg" alt=""></p>
<h2 id="knockknockåœ¨é’‰é’‰ç¾¤ä¸­çš„é…ç½®æ–¹å¼"><a href="#knockknockåœ¨é’‰é’‰ç¾¤ä¸­çš„é…ç½®æ–¹å¼" class="headerlink" title="knockknockåœ¨é’‰é’‰ç¾¤ä¸­çš„é…ç½®æ–¹å¼"></a><a href="https://github.com/huggingface/knockknock" target="_blank" rel="noopener">knockknock</a>åœ¨é’‰é’‰ç¾¤ä¸­çš„é…ç½®æ–¹å¼</h2><p>ä¹‹æ‰€ä»¥é€‰æ‹©ä½¿ç”¨é’‰é’‰ï¼Œæ˜¯å› ä¸ºå®ƒçš„é€šçŸ¥å£°éŸ³æ¯”è¾ƒå¥½å¬ğŸ¤­ã€‚é…ç½®è¿‡ç¨‹ï¼š</p>
<ol>
<li><p>å»ºç«‹é’‰é’‰ç¾¤ï¼ˆæœ€å¥½æ˜¯åœ¨ç”µè„‘ï¼‰</p>
</li>
<li><p>æ·»åŠ æœºå™¨äºº</p>
<p>2.1 ç¾¤è®¾ç½®$\rightarrow $æ™ºèƒ½ç¾¤åŠ©æ‰‹$\rightarrow $æ·»åŠ æœºå™¨äºº</p>
<p>2.2 æ·»åŠ è‡ªå®šä¹‰æœºå™¨äºº</p>
<p>2.3 è‡ªå®šä¹‰åå­—å’Œå¤´åƒ</p>
<p>2.4 é€‰æ‹©ä¸€ç§åŠ å¯†æ–¹å¼ï¼Œæ¨èé€‰æ‹©<code>åŠ ç­¾</code></p>
<p>2.5 è®°å½•å¥½<code>æœºå™¨äººçš„url</code>å’ŒåŠ ç­¾ç”Ÿæˆçš„<code>å¯†é’¥</code></p>
</li>
<li><p>åœ¨notebookæˆ–è€…pythonè™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…knockknock</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!pip install knockknock(notebook)</span><br><span class="line"><span class="keyword">or</span></span><br><span class="line">pip install knockknock(è™šæ‹Ÿç¯å¢ƒ)</span><br></pre></td></tr></table></figure>
</li>
<li><p>å¯¼å…¥dingtalk_sender</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> knockknock <span class="keyword">import</span> dingtalk_sender</span><br></pre></td></tr></table></figure>
</li>
<li><p>åœ¨è¦è·‘çš„ç±»ä¸Šæ·»åŠ ä»¥ä¸‹ä»£ç </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">webhook_url = <span class="string">"https://oapi.dingtalk.com/robot/send?access_token=..."</span></span><br><span class="line"><span class="meta">@dingtalk_sender(webhook_url=webhook_url, secret="åŠ ç­¾ç”Ÿæˆçš„å¯†é’¥", keywords=["éšä¾¿å¡«"])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_your_nicest_model</span><span class="params">(your_nicest_parameters)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    time.sleep(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'loss'</span>: <span class="number">0.9</span>&#125; <span class="comment"># Optional return value</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>è¿è¡Œtrain_your_nicest_modelï¼Œå¾—åˆ°ç»“æœ</p>
<p><img src="https://i.loli.net/2020/05/14/vzGJgxiVu5j2Scb.jpg" alt="å¾®ä¿¡å›¾ç‰‡_20200514211147"></p>
</li>
</ol>
<h2 id="å‚è€ƒæ–‡çŒ®"><a href="#å‚è€ƒæ–‡çŒ®" class="headerlink" title="å‚è€ƒæ–‡çŒ®"></a>å‚è€ƒæ–‡çŒ®</h2><p>æœ¬æ–‡ä¸»è¦å‚è€ƒè‡ªå®˜æ–¹<a href="https://github.com/huggingface/knockknock" target="_blank" rel="noopener">githubä»“åº“</a></p>
<p>ä»¥åŠ<a href="https://ding-doc.dingtalk.com/doc#/serverapi2/qf2nxq" target="_blank" rel="noopener">é˜¿é‡Œé’‰é’‰å¼€å‘è€…å¹³å°</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://dxzmpk.github.io/2020/04/29/Bert%E7%B3%BB%E5%88%97%E4%BC%B4%E7%94%9F%E7%9A%84%E6%96%B0%E5%88%86%E8%AF%8D%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="è‘£é›„">
      <meta itemprop="description" content="Learning in Harbin Institute of Technology">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="è‘£é›„å†™å­—çš„åœ°æ–¹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/29/Bert%E7%B3%BB%E5%88%97%E4%BC%B4%E7%94%9F%E7%9A%84%E6%96%B0%E5%88%86%E8%AF%8D%E5%99%A8/" class="post-title-link" itemprop="url">Bertç³»åˆ—ä¼´ç”Ÿçš„æ–°åˆ†è¯å™¨</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">å‘è¡¨äº</span>

              <time title="åˆ›å»ºæ—¶é—´ï¼š2020-04-29 09:31:52" itemprop="dateCreated datePublished" datetime="2020-04-29T09:31:52+08:00">2020-04-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-04 09:53:09" itemprop="dateModified" datetime="2020-05-04T09:53:09+08:00">2020-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
            </span>

          
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="æ¦‚æ‹¬"><a href="#æ¦‚æ‹¬" class="headerlink" title="æ¦‚æ‹¬"></a>æ¦‚æ‹¬</h2><p>è¿™ç¯‡æ–‡ç« å°†å¯¹Bertç­‰æ¨¡å‹ä½¿ç”¨çš„åˆ†è¯æŠ€æœ¯è¿›è¡Œä»‹ç»ã€‚åŒæ—¶ä¼šæ¶‰åŠè¿™äº›åˆ†è¯å™¨åœ¨huggingface <a href="https://github.com/huggingface/tokenizers" target="_blank" rel="noopener">tokenizers</a>åº“ä¸­çš„ä½¿ç”¨ã€‚ç†è§£è¿™äº›åˆ†è¯å™¨çš„åŸç†ï¼Œå¯¹äºçµæ´»ä½¿ç”¨transformersåº“ä¸­çš„ä¸åŒæ¨¡å‹éå¸¸é‡è¦ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜èƒ½å°†è¿™äº›åˆ†è¯å™¨ç”¨äºå…¶ä»–ä»»åŠ¡ä¸­ï¼Œå¦‚æœæœ‰å¿…è¦çš„è¯ï¼Œæˆ‘ä»¬è¿˜èƒ½è‡ªå·±è®­ç»ƒåˆ†è¯å™¨ã€‚</p>
<h2 id="åˆ†è¯å™¨æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ"><a href="#åˆ†è¯å™¨æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ" class="headerlink" title="åˆ†è¯å™¨æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ"></a>åˆ†è¯å™¨æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ</h2><p><strong>æœºå™¨æ— æ³•ç†è§£æ–‡æœ¬ã€‚</strong>å½“æˆ‘ä»¬å°†å¥å­åºåˆ—é€å…¥æ¨¡å‹æ—¶ï¼Œæ¨¡å‹ä»…ä»…èƒ½çœ‹åˆ°ä¸€ä¸²å­—èŠ‚ï¼Œå®ƒæ— æ³•çŸ¥é“ä¸€ä¸ªè¯ä»å“ªé‡Œå¼€å§‹ï¼Œåˆ°å“ªé‡Œç»“æŸï¼Œæ‰€ä»¥ä¹Ÿä¸çŸ¥é“ä¸€ä¸ªè¯æ˜¯æ€ä¹ˆç»„æˆçš„ã€‚</p>
<p>â€‹    æ‰€ä»¥ï¼Œä¸ºäº†å¸®åŠ©æœºå™¨ç†è§£æ–‡æœ¬ï¼Œæˆ‘ä»¬éœ€è¦</p>
<ol>
<li>å°†æ–‡æœ¬åˆ†æˆä¸€ä¸ªä¸ªå°ç‰‡æ®µ</li>
<li>ç„¶åå°†è¿™äº›ç‰‡æ®µè¡¨ç¤ºä¸ºä¸€ä¸ªå‘é‡ä½œä¸ºæ¨¡å‹çš„è¾“å…¥</li>
<li>åŒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦å°†ä¸€ä¸ªä¸ªå°ç‰‡æ®µï¼ˆtoken) è¡¨ç¤ºä¸ºå‘é‡ï¼Œä½œä¸ºè¯åµŒå…¥çŸ©é˜µï¼Œ é€šè¿‡åœ¨è¯­æ–™åº“ä¸Šè®­ç»ƒæ¥ä¼˜åŒ–tokençš„è¡¨ç¤ºï¼Œä½¿å…¶è•´å«æ›´å¤šæœ‰ç”¨çš„ä¿¡æ¯ï¼Œç”¨äºä¹‹åçš„ä»»åŠ¡ã€‚</li>
</ol>
<h2 id="å¤å…¸åˆ†è¯æ–¹æ³•"><a href="#å¤å…¸åˆ†è¯æ–¹æ³•" class="headerlink" title="å¤å…¸åˆ†è¯æ–¹æ³•"></a>å¤å…¸åˆ†è¯æ–¹æ³•</h2><p><img src="/images/Bert%E7%B3%BB%E5%88%97%E4%BC%B4%E7%94%9F%E7%9A%84%E6%96%B0%E5%88%86%E8%AF%8D%E5%99%A8/tokenize.png" alt="tokenize"></p>
<h3 id="åŸºäºç©ºæ ¼çš„åˆ†è¯æ–¹æ³•"><a href="#åŸºäºç©ºæ ¼çš„åˆ†è¯æ–¹æ³•" class="headerlink" title="åŸºäºç©ºæ ¼çš„åˆ†è¯æ–¹æ³•"></a>åŸºäºç©ºæ ¼çš„åˆ†è¯æ–¹æ³•</h3><p>ä¸€ä¸ªå¥å­ï¼Œä½¿ç”¨ä¸åŒçš„è§„åˆ™ï¼Œå°†æœ‰è®¸å¤šç§ä¸åŒçš„åˆ†è¯ç»“æœã€‚æˆ‘ä»¬ä¹‹å‰å¸¸ç”¨çš„åˆ†è¯æ–¹æ³•å°†ç©ºæ ¼ä½œä¸ºåˆ†è¯çš„è¾¹ç•Œã€‚ä¹Ÿå°±æ˜¯å›¾ä¸­çš„ç¬¬ä¸‰ç§æ–¹æ³•ã€‚ä½†æ˜¯ï¼Œè¿™ç§æ–¹æ³•å­˜åœ¨é—®é¢˜ï¼Œå³åªæœ‰åœ¨è®­ç»ƒè¯­æ–™ä¸­å‡ºç°çš„tokenæ‰èƒ½è¢«è®­ç»ƒå™¨å­¦ä¹ åˆ°ï¼Œè€Œé‚£äº›æ²¡æœ‰å‡ºç°çš„tokenå°†ä¼šè¢«<code>&lt;UNK&gt;</code>ç­‰ç‰¹æ®Šæ ‡è®°ä»£æ›¿ï¼Œè¿™æ ·å°†å½±å“æ¨¡å‹çš„è¡¨ç°ã€‚å¦‚æœæˆ‘ä»¬å°†è¯å…¸åšå¾—è¶³å¤Ÿå¤§ï¼Œä½¿å…¶èƒ½å®¹çº³æ‰€æœ‰çš„å•è¯ã€‚é‚£ä¹ˆè¯å…¸å°†éå¸¸åºå¤§ï¼Œäº§ç”Ÿå¾ˆå¤§çš„å¼€é”€ã€‚åŒæ—¶å¯¹äºå‡ºç°æ¬¡æ•°å¾ˆå°‘çš„è¯ï¼Œå­¦ä¹ å…¶tokençš„å‘é‡è¡¨ç¤ºä¹Ÿéå¸¸å›°éš¾ã€‚é™¤å»è¿™äº›åŸå› ï¼Œæœ‰å¾ˆå¤šè¯­è¨€ä¸ç”¨ç©ºæ ¼è¿›è¡Œåˆ†è¯ï¼Œä¹Ÿå°±æ— æ³•ä½¿ç”¨åŸºäºç©ºæ ¼åˆ†è¯çš„æ–¹æ³•ã€‚ç»¼ä¸Šï¼Œæˆ‘ä»¬éœ€è¦æ–°çš„åˆ†è¯æ–¹æ³•æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</p>
<h3 id="åŸºäºå­—æ¯çš„åˆ†è¯æ–¹æ³•"><a href="#åŸºäºå­—æ¯çš„åˆ†è¯æ–¹æ³•" class="headerlink" title="åŸºäºå­—æ¯çš„åˆ†è¯æ–¹æ³•"></a>åŸºäºå­—æ¯çš„åˆ†è¯æ–¹æ³•</h3><p>ç®€å•æ¥è¯´ï¼Œå°±æ˜¯å°†æ¯ä¸ªå­—ç¬¦çœ‹ä½œä¸€ä¸ªè¯ã€‚</p>
<p><strong>ä¼˜ç‚¹</strong>ï¼š ä¸ç”¨æ‹…å¿ƒæœªçŸ¥è¯æ±‡ï¼Œå¯ä»¥ä¸ºæ¯ä¸€ä¸ªå•è¯ç”Ÿæˆè¯åµŒå…¥å‘é‡è¡¨ç¤ºã€‚</p>
<p><strong>ç¼ºç‚¹</strong>ï¼š</p>
<ul>
<li>å­—æ¯æœ¬èº«å°±æ²¡æœ‰ä»»ä½•çš„å†…åœ¨å«ä¹‰ï¼Œå¾—åˆ°çš„è¯åµŒå…¥å‘é‡ç¼ºä¹å«ä¹‰ã€‚</li>
<li>è®¡ç®—å¤æ‚åº¦æå‡ï¼ˆå­—æ¯çš„æ•°ç›®è¿œå¤§äºtokençš„æ•°ç›®ï¼‰</li>
<li>è¾“å‡ºåºåˆ—çš„é•¿åº¦å°†å˜å¤§ï¼Œå¯¹äºBertã€CNNç­‰é™åˆ¶æœ€å¤§é•¿åº¦çš„æ¨¡å‹å°†å¾ˆå®¹æ˜“è¾¾åˆ°æœ€å¤§å€¼ã€‚</li>
</ul>
<h2 id="åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•ï¼ˆSubword-Tokenizationï¼‰"><a href="#åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•ï¼ˆSubword-Tokenizationï¼‰" class="headerlink" title="åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•ï¼ˆSubword Tokenizationï¼‰"></a>åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•ï¼ˆSubword Tokenizationï¼‰</h2><p>ä¸ºäº†æ”¹è¿›åˆ†è¯æ–¹æ³•ï¼Œåœ¨<code>&lt;UNK&gt;</code>æ•°ç›®å’Œè¯å‘é‡å«ä¹‰ä¸°å¯Œæ€§ä¹‹é—´è¾¾åˆ°å¹³è¡¡ï¼Œæå‡ºäº†Subword Tokenizationæ–¹æ³•ã€‚è¿™ç§æ–¹æ³•çš„ç›®çš„æ˜¯é€šè¿‡ä¸€ä¸ªæœ‰é™çš„å•è¯åˆ—è¡¨æ¥è§£å†³æ‰€æœ‰å•è¯çš„åˆ†è¯é—®é¢˜ï¼ŒåŒæ—¶å°†ç»“æœä¸­tokençš„æ•°ç›®é™åˆ°æœ€ä½ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨æ›´å°çš„è¯ç‰‡æ®µæ¥ç»„æˆæ›´å¤§çš„è¯ï¼š</p>
<p>â€œ<strong><em>unfortunately</em></strong>â€ = â€œ<strong><em>un</em></strong>â€ + â€œ<strong><em>for</em></strong>â€ + â€œ<strong><em>tun</em></strong>â€ + â€œ<strong><em>ate</em></strong>â€ + â€œ<strong><em>ly</em></strong>â€ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œå°†ä»‹ç»å‡ ç§ä¸åŒçš„Subword Tokenizationæ–¹æ³•ã€‚</p>
<h3 id="Byte-Pair-Encoding-BPE-å­—èŠ‚å¯¹ç¼–ç "><a href="#Byte-Pair-Encoding-BPE-å­—èŠ‚å¯¹ç¼–ç " class="headerlink" title="Byte Pair Encoding (BPE) å­—èŠ‚å¯¹ç¼–ç "></a>Byte Pair Encoding (BPE) å­—èŠ‚å¯¹ç¼–ç </h3><h3 id="æ¦‚è¿°"><a href="#æ¦‚è¿°" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>å­—èŠ‚å¯¹ç¼–ç æœ€æ—©æ˜¯åœ¨ä¿¡å·å‹ç¼©é¢†åŸŸæå‡ºçš„ï¼Œåæ¥è¢«åº”ç”¨äºåˆ†è¯ä»»åŠ¡ä¸­ã€‚åœ¨ä¿¡å·å‹ç¼©é¢†åŸŸä¸­BPEè¿‡ç¨‹å¯è§†åŒ–å¦‚ä¸‹ï¼š</p>
<p><img src="/images/Bert%E7%B3%BB%E5%88%97%E4%BC%B4%E7%94%9F%E7%9A%84%E6%96%B0%E5%88%86%E8%AF%8D%E5%99%A8/1_x1Y_n3sXGygUPSdfXTm9pQ.gif" alt="1_x1Y_n3sXGygUPSdfXTm9pQ"></p>
<p>æ¥ä¸‹æ¥é‡ç‚¹ä»‹ç»å°†BPEåº”ç”¨äºåˆ†è¯ä»»åŠ¡çš„æµç¨‹ï¼š</p>
<h3 id="å®ç°æµç¨‹"><a href="#å®ç°æµç¨‹" class="headerlink" title="å®ç°æµç¨‹"></a>å®ç°æµç¨‹</h3><ol>
<li>æ ¹æ®è¯­æ–™åº“å»ºç«‹ä¸€ä¸ªè¯å…¸ï¼Œè¯å…¸ä¸­ä»…åŒ…å«å•ä¸ªå­—ç¬¦ï¼Œå¦‚è‹±æ–‡ä¸­å°±æ˜¯a-z</li>
<li>ç»Ÿè®¡è¯­æ–™åº“ä¸­å‡ºç°æ¬¡æ•°æœ€å¤šçš„å­—ç¬¦å¯¹ï¼ˆè¯å…¸ä¸­ä¸¤é¡¹çš„ç»„åˆï¼‰ï¼Œç„¶åå°†å­—ç¬¦å¯¹åŠ å…¥åˆ°è¯å…¸ä¸­</li>
<li>é‡å¤æ­¥éª¤2ç›´åˆ°åˆ°è¾¾è§„å®šçš„æ­¥éª¤æ•°ç›®æˆ–è€…è¯å…¸å°ºå¯¸ç¼©å°åˆ°äº†æŒ‡å®šçš„å€¼ã€‚</li>
</ol>
<h3 id="BPEçš„ä¼˜ç‚¹"><a href="#BPEçš„ä¼˜ç‚¹" class="headerlink" title="BPEçš„ä¼˜ç‚¹"></a>BPEçš„ä¼˜ç‚¹</h3><p>å¯ä»¥å¾ˆæœ‰æ•ˆåœ°å¹³è¡¡è¯å…¸å°ºå¯¸å’Œç¼–ç æ­¥éª¤æ•°(å°†å¥å­ç¼–ç æ‰€éœ€è¦çš„tokenæ•°é‡)</p>
<h3 id="BPEå­˜åœ¨çš„ç¼ºç‚¹ï¼š"><a href="#BPEå­˜åœ¨çš„ç¼ºç‚¹ï¼š" class="headerlink" title="BPEå­˜åœ¨çš„ç¼ºç‚¹ï¼š"></a><strong>BPE</strong>å­˜åœ¨çš„ç¼ºç‚¹ï¼š</h3><p><img src="/images/Bert%E7%B3%BB%E5%88%97%E4%BC%B4%E7%94%9F%E7%9A%84%E6%96%B0%E5%88%86%E8%AF%8D%E5%99%A8/image-20200429104839759.png" alt="image-20200429104839759"></p>
<ul>
<li>å¯¹äºåŒä¸€ä¸ªå¥å­, ä¾‹å¦‚Hello worldï¼Œå¦‚å›¾æ‰€ç¤ºï¼Œå¯èƒ½ä¼šæœ‰ä¸åŒçš„Subwordåºåˆ—ã€‚ä¸åŒçš„Subwordåºåˆ—ä¼šäº§ç”Ÿå®Œå…¨ä¸åŒçš„idåºåˆ—è¡¨ç¤ºï¼Œè¿™ç§æ­§ä¹‰å¯èƒ½åœ¨è§£ç é˜¶æ®µæ— æ³•è§£å†³ã€‚åœ¨ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œä¸åŒçš„idåºåˆ—å¯èƒ½ç¿»è¯‘å‡ºä¸åŒçš„å¥å­ï¼Œè¿™æ˜¾ç„¶æ˜¯é”™è¯¯çš„ã€‚</li>
<li>åœ¨è®­ç»ƒä»»åŠ¡ä¸­ï¼Œå¦‚æœèƒ½å¯¹ä¸åŒçš„Subwordè¿›è¡Œè®­ç»ƒçš„è¯ï¼Œå°†å¢åŠ æ¨¡å‹çš„å¥å£®æ€§ï¼Œèƒ½å¤Ÿå®¹å¿æ›´å¤šçš„å™ªå£°ï¼Œè€ŒBPEçš„è´ªå¿ƒç®—æ³•æ— æ³•å¯¹éšæœºåˆ†å¸ƒè¿›è¡Œå­¦ä¹ ã€‚</li>
</ul>
<h3 id="Unigram-Based-Tokenization"><a href="#Unigram-Based-Tokenization" class="headerlink" title="Unigram Based Tokenization"></a>Unigram Based Tokenization</h3><h3 id="æ–¹æ³•æ¦‚è¿°"><a href="#æ–¹æ³•æ¦‚è¿°" class="headerlink" title="æ–¹æ³•æ¦‚è¿°"></a>æ–¹æ³•æ¦‚è¿°</h3><p>åˆ†è¯ä¸­çš„Unigramæ¨¡å‹æ˜¯<strong>Kudo.</strong>åœ¨è®ºæ–‡<strong>â€œSubword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidatesâ€</strong>ä¸­æå‡ºçš„ã€‚å½“æ—¶ä¸»è¦æ˜¯ä¸ºäº†è§£å†³æœºå™¨ç¿»è¯‘ä¸­åˆ†è¯çš„é—®é¢˜ã€‚ä½œè€…ä½¿ç”¨ä¸€ç§å«åš<code>marginalized likelihood</code>çš„æ–¹æ³•æ¥å»ºæ¨¡ç¿»è¯‘é—®é¢˜ï¼Œè€ƒè™‘åˆ°ä¸åŒåˆ†è¯ç»“æœå¯¹æœ€ç»ˆç¿»è¯‘ç»“æœçš„å½±å“ï¼Œå¼•å…¥äº†åˆ†è¯æ¦‚ç‡$P(\vec{x}|X)$æ¥è¡¨ç¤º$X$æœ€ç»ˆåˆ†è¯ä¸º$\vec{x}$çš„æ¦‚ç‡(Xä¸ºåŸå§‹çš„å¥å­, $\vec{x}$ä¸ºåˆ†è¯çš„ç»“æœ$\vec{x} = (x_1, . . . , x_M) $ï¼Œç”±å¤šä¸ªsubwordç»„æˆ)ã€‚ä¼ ç»Ÿçš„BPEç®—æ³•æ— æ³•å¯¹è¿™ä¸ªæ¦‚ç‡è¿›è¡Œå»ºæ¨¡ï¼Œå› æ­¤ä½œè€…ä½¿ç”¨äº†Unigramè¯­è¨€æ¨¡å‹æ¥è¾¾åˆ°è¿™æ ·çš„ç›®çš„ã€‚</p>
<h3 id="æ–¹æ³•æ‰§è¡Œè¿‡ç¨‹"><a href="#æ–¹æ³•æ‰§è¡Œè¿‡ç¨‹" class="headerlink" title="æ–¹æ³•æ‰§è¡Œè¿‡ç¨‹"></a>æ–¹æ³•æ‰§è¡Œè¿‡ç¨‹</h3><p><strong>å‡è®¾</strong>ï¼šæ ¹æ®unigramçš„å‡è®¾ï¼Œæ¯ä¸ªå­—è¯çš„å‡ºç°æ˜¯ç‹¬ç«‹çš„ã€‚æ‰€ä»¥</p>
<script type="math/tex; mode=display">
P(\vec{x}) = \prod_{i=1}^{M}p(x_i)</script><p>è¿™é‡Œçš„$x_i$æ˜¯ä»é¢„å…ˆå®šä¹‰å¥½çš„è¯å…¸$V$ä¸­å–å¾—çš„ï¼Œæ‰€ä»¥ï¼Œæœ€æœ‰å¯èƒ½çš„åˆ†è¯æ–¹å¼å°±å¯ä»¥è¿™æ ·è¡¨ç¤ºï¼š</p>
<script type="math/tex; mode=display">
x^* =\underset{x\in S(X)}{arg\;max}\;P(\vec{x})</script><p>è¿™é‡Œ$S(X)$æ˜¯å¥å­$X$ä¸åŒçš„åˆ†è¯ç»“æœé›†åˆã€‚$x^*$å¯ä»¥é€šè¿‡ç»´ç‰¹æ¯”ç®—æ³•å¾—åˆ°ã€‚</p>
<p>å¦‚æœå·²çŸ¥è¯å…¸$V$, æˆ‘ä»¬å¯ä»¥é€šè¿‡EMç®—æ³•æ¥ä¼°è®¡$p(x_i)$ï¼Œå…¶ä¸­Mæ­¥æœ€å¤§åŒ–çš„å¯¹è±¡æ˜¯ä»¥ä¸‹ä¼¼ç„¶å‡½æ•°ï¼ˆåŸè°…æˆ‘è¿™é‡Œå·æ‡’ç›´æ¥ä½¿ç”¨å›¾ç‰‡ï¼‰ï¼š</p>
<p><img src="/images/Bert%E7%B3%BB%E5%88%97%E4%BC%B4%E7%94%9F%E7%9A%84%E6%96%B0%E5%88%86%E8%AF%8D%E5%99%A8/image-20200501185312612.png" alt="image-20200501185312612"></p>
<p>$|D|$æ˜¯è¯­æ–™åº“ä¸­è¯­æ–™æ•°é‡ã€‚</p>
<p><strong>æˆ‘æ˜¯è¿™æ ·ç†è§£è¿™ä¸ªä¼¼ç„¶å‡½æ•°çš„ï¼š</strong>å°†è¯­æ–™åº“ä¸­æ‰€æœ‰å¥å­çš„æ‰€æœ‰åˆ†è¯ç»„åˆå½¢æˆçš„æ¦‚ç‡ç›¸åŠ ã€‚</p>
<p>åˆå§‹æ—¶ï¼Œæˆ‘ä»¬è¿è¯å…¸$V$éƒ½æ²¡æœ‰ï¼Œä½œè€…é€šè¿‡ä¸æ–­æ‰§è¡Œä»¥ä¸‹æ­¥éª¤æ¥æ„é€ åˆé€‚çš„è¯å…¸ä»¥åŠåˆ†è¯æ¦‚ç‡ï¼š</p>
<ol>
<li><p>ä»å¤´æ„å»ºä¸€ä¸ªç›¸å½“å¤§çš„ç§å­è¯å…¸ã€‚</p>
</li>
<li><p>é‡å¤ä»¥ä¸‹æ­¥éª¤ï¼ŒçŸ¥é“å­—å…¸å°ºå¯¸$|V|$å‡å°åˆ°æœŸæœ›å€¼ï¼š</p>
<ul>
<li><p>å›ºå®šè¯å…¸ï¼Œé€šè¿‡EMç®—æ³•ä¼˜åŒ–$p(x)$</p>
</li>
<li><p>ä¸ºæ¯ä¸€ä¸ªå­è¯è®¡ç®—$loss_i$ï¼Œlossä»£è¡¨å¦‚æœå°†æŸä¸ªè¯å»æ‰ï¼Œä¸Šè¿°ä¼¼ç„¶å‡½æ•°å€¼ä¼šå‡å°‘å¤šå°‘ã€‚æ ¹æ®lossæ’åºï¼Œä¿ç•™lossæœ€é«˜çš„$\eta$ä¸ªå­è¯ã€‚æ³¨æ„ï¼šä¿ç•™æ‰€æœ‰çš„å•å­—ç¬¦ï¼Œä»è€Œé¿å…OOVæƒ…å†µã€‚</p>
<p><strong>æˆ‘æ˜¯è¿™æ ·ç†è§£lossçš„ï¼š</strong>è‹¥æŸä¸ªå­è¯ç»å¸¸ä»¥å¾ˆé«˜çš„é¢‘ç‡å‡ºç°åœ¨å¾ˆå¤šå¥å­çš„åˆ†è¯ç»“æœä¸­ï¼Œé‚£ä¹ˆå…¶æŸå¤±å°†ä¼šå¾ˆå¤§ï¼Œæ‰€ä»¥è¦ä¿ç•™è¿™æ ·çš„å­è¯ã€‚</p>
</li>
</ul>
</li>
</ol>
<h3 id="ä¸»è¦è´¡çŒ®ï¼š"><a href="#ä¸»è¦è´¡çŒ®ï¼š" class="headerlink" title="ä¸»è¦è´¡çŒ®ï¼š"></a>ä¸»è¦è´¡çŒ®ï¼š</h3><ol>
<li>ä½¿ç”¨çš„è®­ç»ƒç®—æ³•å¯ä»¥åˆ©ç”¨æ‰€æœ‰å¯èƒ½çš„åˆ†è¯ç»“æœï¼Œè¿™æ˜¯é€šè¿‡data samplingç®—æ³•å®ç°çš„ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºè¯­è¨€æ¨¡å‹çš„åˆ†è¯ç®—æ³•ï¼Œè¿™ç§è¯­è¨€æ¨¡å‹å¯ä»¥ç»™å¤šç§åˆ†è¯ç»“æœèµ‹äºˆæ¦‚ç‡ï¼Œä»è€Œå¯ä»¥å­¦å¾—å…¶ä¸­çš„å™ªå£°ã€‚</li>
</ol>
<h2 id="å°†åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•åº”ç”¨åˆ°å®é™…ä¸­"><a href="#å°†åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•åº”ç”¨åˆ°å®é™…ä¸­" class="headerlink" title="å°†åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•åº”ç”¨åˆ°å®é™…ä¸­"></a>å°†åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•åº”ç”¨åˆ°å®é™…ä¸­</h2><h3 id="Bertä¸­çš„WordPieceåˆ†è¯å™¨"><a href="#Bertä¸­çš„WordPieceåˆ†è¯å™¨" class="headerlink" title="Bertä¸­çš„WordPieceåˆ†è¯å™¨"></a>Bertä¸­çš„WordPieceåˆ†è¯å™¨</h3><p>WordPieceæ˜¯éšç€Bertè®ºæ–‡çš„å‡ºç°è¢«æå‡ºçš„ã€‚åœ¨æ•´ä½“æ­¥éª¤ä¸Šï¼ŒWordPieceæ–¹æ³•å’ŒBPEæ˜¯ç›¸åŒçš„ã€‚å³ä¹Ÿæ˜¯è‡ªä½å‘ä¸Šåœ°æ„å»ºè¯å…¸ã€‚åŒºåˆ«æ˜¯BPEåœ¨æ¯æ¬¡åˆå¹¶çš„æ—¶å€™éƒ½é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€é«˜çš„å­—ç¬¦å¯¹ï¼Œè€ŒWordPieceä½¿ç”¨çš„æ˜¯ç±»ä¼¼äºUnigramçš„æ–¹æ³•ï¼Œå³é€šè¿‡è¯­è¨€æ¨¡å‹æ¥å¾—åˆ°åˆå¹¶ä¸¤ä¸ªå•è¯å¯èƒ½é€ æˆçš„å½±å“ï¼Œç„¶åé€‰æ‹©ä½¿å¾—ä¼¼ç„¶å‡½æ•°æå‡æœ€å¤§çš„å­—ç¬¦å¯¹ã€‚è¿™ä¸ªæå‡æ˜¯é€šè¿‡ç»“åˆåçš„å­—ç¬¦å¯¹å‡å»ç»“åˆå‰çš„å­—ç¬¦å¯¹ä¹‹å’Œå¾—åˆ°çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåˆ¤æ–­â€œdeâ€ç›¸è¾ƒäºâ€œdâ€+â€eâ€æ˜¯å¦æ›´é€‚åˆå‡ºç°ã€‚</p>
<p>ä¸‰ç§åˆ†è¯å™¨çš„å…³ç³»å¦‚ä¸‹ï¼š(å›¾è‡ª<a href="https://blog.floydhub.com/tokenization-nlp/" target="_blank" rel="noopener">FloudHub Blog</a>)</p>
<p><img src="/images/Bert%E7%B3%BB%E5%88%97%E4%BC%B4%E7%94%9F%E7%9A%84%E6%96%B0%E5%88%86%E8%AF%8D%E5%99%A8/subword-probabilistic-tokenization.png" alt="Frequency V probability approaches"></p>
<h3 id="SentencePieceåº“"><a href="#SentencePieceåº“" class="headerlink" title="SentencePieceåº“"></a>SentencePieceåº“</h3><p>SentencePieceæ˜¯åœ¨â€œSentencePiece: A simple and language independent subword tokenizer<br>and detokenizer for Neural Text Processingâ€è¿™ç¯‡æ–‡ç« ä¸­ä»‹ç»çš„ã€‚å…¶ä¸»è¦æ˜¯ä¸ºäº†è§£å†³ä¸åŒè¯­è¨€åˆ†è¯è§„åˆ™éœ€è¦ç‰¹åˆ«å®šä¹‰çš„é—®é¢˜ï¼Œæ¯”å¦‚ä¸‹é¢è¿™ç§æƒ…å†µï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Raw text: Hello world.</span><br><span class="line">Tokenized: [Hello] [world] [.]</span><br><span class="line">Decoded text: Hello world .</span><br></pre></td></tr></table></figure>
<p>å°†åˆ†è¯ç»“æœè§£ç åˆ°åŸæ¥çš„å¥å­ä¸­æ—¶ï¼Œä¼šåœ¨ä¸åŒçš„è¯ä¹‹é—´æ·»åŠ ç©ºæ ¼ï¼Œç”Ÿæˆ<code>Decoded text</code>æ‰€ç¤ºçš„ç»“æœï¼Œè¿™å°±æ˜¯ç¼–ç è§£ç å‡ºç°çš„æ­§ä¹‰æ€§ï¼Œå› æ­¤éœ€è¦ç‰¹åˆ«å®šä¹‰è§„åˆ™æ¥å®ç°äº’é€†ã€‚è¿˜æœ‰ä¸€ä¸ªä¾‹å­æ˜¯ï¼Œåœ¨è§£ç é˜¶æ®µï¼Œæ¬§æ´²è¯­è¨€è¯ä¹‹é—´è¦æ·»åŠ ç©ºæ ¼ï¼Œè€Œä¸­æ–‡ç­‰è¯­è¨€åˆ™ä¸åº”æ·»åŠ ç©ºæ ¼ã€‚å¯¹äºè¿™ç§åŒºåˆ«ï¼Œä¹Ÿéœ€è¦å•ç‹¬å®šåˆ¶è§„åˆ™ï¼Œè¿™äº›ç¹æ‚çš„è§„åˆ™ç»´æŠ¤èµ·æ¥éå¸¸å›°éš¾ï¼Œæ‰€ä»¥ä½œè€…é‡‡ç”¨ä»¥ä¸‹çš„æ–¹æ¡ˆæ¥è§£å†³ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">å°†æ‰€æœ‰çš„å­—ç¬¦éƒ½è½¬åŒ–æˆUnicodeç¼–ç ï¼Œç©ºæ ¼ç”¨â€˜_â€™æ¥ä»£æ›¿ï¼Œç„¶åè¿›è¡Œåˆ†è¯æ“ä½œã€‚è¿™æ ·ç©ºæ ¼ä¹Ÿä¸éœ€è¦ç‰¹åˆ«å®šä¹‰è§„åˆ™äº†ã€‚ç„¶ååœ¨è§£ç ç»“æŸåï¼Œä½¿ç”¨Pythonä»£ç æ¢å¤å³å¯ï¼š</span><br><span class="line">detok = â€™â€™.join(tokens).replace(â€™_â€™, â€™ â€™)</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/google/sentencepiece" target="_blank" rel="noopener">SentencePieceåº“</a>ä¸»è¦ç”±ä»¥ä¸‹éƒ¨åˆ†ç»„æˆï¼š</p>
<p><strong>â€œNormalizer, Trainer, Encoder,  Decoderâ€</strong></p>
<p>å…¶ä¸­Normalizerç”¨æ¥å¯¹Unicodeç¼–ç è¿›è¡Œè§„èŒƒåŒ–ï¼Œè¿™é‡Œä½¿ç”¨çš„ç®—æ³•æ˜¯<code>NFKC</code>æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒè‡ªå®šä¹‰è§„èŒƒåŒ–æ–¹æ³•ã€‚Traineråˆ™ç”¨æ¥è®­ç»ƒåˆ†è¯æ¨¡å‹ã€‚Encoderæ˜¯å°†å¥å­å˜æˆç¼–ç ï¼Œè€ŒDecoderæ˜¯åå‘æ“ä½œã€‚ä»–ä»¬ä¹‹é—´å­˜åœ¨ä»¥ä¸‹å‡½æ•°å…³ç³»ï¼š</p>
<script type="math/tex; mode=display">
Decode(Encode(Normalize(text))) = Normalize(text):</script><h3 id="Huggingface-tokenizersåº“çš„ä»‹ç»å’Œä½¿ç”¨"><a href="#Huggingface-tokenizersåº“çš„ä»‹ç»å’Œä½¿ç”¨" class="headerlink" title="Huggingface tokenizersåº“çš„ä»‹ç»å’Œä½¿ç”¨"></a>Huggingface tokenizersåº“çš„ä»‹ç»å’Œä½¿ç”¨</h3><p><a href="https://github.com/huggingface/tokenizers" target="_blank" rel="noopener">tokenizers</a>æ˜¯é›†åˆäº†å½“å‰æœ€å¸¸ç”¨çš„åˆ†è¯å™¨é›†åˆï¼Œæ•ˆç‡å’Œæ˜“ç”¨æ€§ä¹Ÿæ˜¯å…¶å…³æ³¨çš„èŒƒç•´ã€‚</p>
<p>ä½¿ç”¨ç¤ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tokenizers provides ultra-fast implementations of most current tokenizers:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> tokenizers <span class="keyword">import</span> (ByteLevelBPETokenizer,</span><br><span class="line">                            CharBPETokenizer,</span><br><span class="line">                            SentencePieceBPETokenizer,</span><br><span class="line">                            BertWordPieceTokenizer)</span><br><span class="line"><span class="comment"># Ultra-fast =&gt; they can encode 1GB of text in ~20sec on a standard server's CPU</span></span><br><span class="line"><span class="comment"># Tokenizers can be easily instantiated from standard files</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer = BertWordPieceTokenizer(<span class="string">"bert-base-uncased-vocab.txt"</span>, lowercase=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenizers provide exhaustive outputs: tokens, mapping to original string, attention/special token masks.</span></span><br><span class="line"><span class="comment"># They also handle model's max input lengths as well as padding (to directly encode in padded batches)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = tokenizer.encode(<span class="string">"Hello, y'all! How are you ğŸ˜ ?"</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(output.ids, output.tokens, output.offsets)</span><br><span class="line">[<span class="number">101</span>, <span class="number">7592</span>, <span class="number">1010</span>, <span class="number">1061</span>, <span class="number">1005</span>, <span class="number">2035</span>, <span class="number">999</span>, <span class="number">2129</span>, <span class="number">2024</span>, <span class="number">2017</span>, <span class="number">100</span>, <span class="number">1029</span>, <span class="number">102</span>]</span><br><span class="line">[<span class="string">'[CLS]'</span>, <span class="string">'hello'</span>, <span class="string">','</span>, <span class="string">'y'</span>, <span class="string">"'"</span>, <span class="string">'all'</span>, <span class="string">'!'</span>, <span class="string">'how'</span>, <span class="string">'are'</span>, <span class="string">'you'</span>, <span class="string">'[UNK]'</span>, <span class="string">'?'</span>, <span class="string">'[SEP]'</span>]</span><br><span class="line">[(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">5</span>), (<span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>), (<span class="number">8</span>, <span class="number">9</span>), (<span class="number">9</span>, <span class="number">12</span>), (<span class="number">12</span>, <span class="number">13</span>), (<span class="number">14</span>, <span class="number">17</span>), (<span class="number">18</span>, <span class="number">21</span>), (<span class="number">22</span>, <span class="number">25</span>), (<span class="number">26</span>, <span class="number">27</span>),(<span class="number">28</span>, <span class="number">29</span>), (<span class="number">0</span>, <span class="number">0</span>)]</span><br><span class="line"><span class="comment"># Here is an example using the offsets mapping to retrieve the string corresponding to the 10th token:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.original_str[output.offsets[<span class="number">10</span>]]</span><br><span class="line"><span class="string">'ğŸ˜'</span></span><br></pre></td></tr></table></figure>
<h3 id="è‡ªå·±è®­ç»ƒåˆ†è¯å™¨"><a href="#è‡ªå·±è®­ç»ƒåˆ†è¯å™¨" class="headerlink" title="è‡ªå·±è®­ç»ƒåˆ†è¯å™¨"></a>è‡ªå·±è®­ç»ƒåˆ†è¯å™¨</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># You can also train a BPE/Byte-levelBPE/WordPiece vocabulary on your own files</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer = ByteLevelBPETokenizer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer.train([<span class="string">"wiki.test.raw"</span>], vocab_size=<span class="number">20000</span>)</span><br><span class="line">[<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>] Tokenize words                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   <span class="number">20993</span>/<span class="number">20993</span></span><br><span class="line">[<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>] Count pairs                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   <span class="number">20993</span>/<span class="number">20993</span></span><br><span class="line">[<span class="number">00</span>:<span class="number">00</span>:<span class="number">03</span>] Compute merges                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   <span class="number">19375</span>/<span class="number">19375</span></span><br></pre></td></tr></table></figure>
<h2 id="å‚è€ƒææ–™"><a href="#å‚è€ƒææ–™" class="headerlink" title="å‚è€ƒææ–™"></a>å‚è€ƒææ–™</h2><p>è¿™ç¯‡æ–‡ç« æ˜¯åœ¨Floydhubçš„<a href="https://blog.floydhub.com/tokenization-nlp/" target="_blank" rel="noopener">ä¸€ç¯‡åšå®¢</a>åŸºç¡€ä¸Šæ‰©å±•çš„ã€‚è¿˜ä¸»è¦å‚è€ƒäº†Unigramçš„åŸè®ºæ–‡ï¼ŒBPEçš„å®˜æ–¹è§£é‡Šç­‰ã€‚BPEçš„åŠ¨æ€å›¾æ¥è‡ªäºToward data scienceçš„<a href="https://towardsdatascience.com/byte-pair-encoding-the-dark-horse-of-modern-nlp-eb36c7df4f10" target="_blank" rel="noopener">æœ‰å…³åšå®¢</a>ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæœ€åä¸€ç« å‚è€ƒäºtokenizersçš„<a href="https://github.com/huggingface/tokenizers" target="_blank" rel="noopener">å®˜æ–¹ä»“åº“</a>ã€‚</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://dxzmpk.github.io/2020/04/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0notebook%E5%A4%9A%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%A0%B7%E6%9C%AC%E4%BB%A3%E7%A0%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="è‘£é›„">
      <meta itemprop="description" content="Learning in Harbin Institute of Technology">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="è‘£é›„å†™å­—çš„åœ°æ–¹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0notebook%E5%A4%9A%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%A0%B7%E6%9C%AC%E4%BB%A3%E7%A0%81/" class="post-title-link" itemprop="url">æ·±åº¦å­¦ä¹ Notebookå¤šæŠ˜äº¤å‰éªŒè¯æ ·æœ¬ä»£ç </a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2020-04-27 11:45:20 / ä¿®æ”¹æ—¶é—´ï¼š12:17:16" itemprop="dateCreated datePublished" datetime="2020-04-27T11:45:20+08:00">2020-04-27</time>
            </span>

          
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="æ·±åº¦å­¦ä¹ notebookå¤šæŠ˜äº¤å‰éªŒè¯æ ·æœ¬ä»£ç "><a href="#æ·±åº¦å­¦ä¹ notebookå¤šæŠ˜äº¤å‰éªŒè¯æ ·æœ¬ä»£ç " class="headerlink" title="æ·±åº¦å­¦ä¹ notebookå¤šæŠ˜äº¤å‰éªŒè¯æ ·æœ¬ä»£ç "></a>æ·±åº¦å­¦ä¹ notebookå¤šæŠ˜äº¤å‰éªŒè¯æ ·æœ¬ä»£ç </h1><p><strong>è¿™ä»½æ ·æœ¬ä»£ç åŸºäº @abhishekâ€™s <a href="https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch" target="_blank" rel="noopener">BERT Base Uncased using PyTorch</a>åœ¨tweetæƒ…æ„Ÿè¯æŠ½å–æ¯”èµ›ä¸Šçš„notebook</strong>, å¦‚æœå†³å®šä½¿ç”¨ä»£ç ï¼Œè¯·ä¸ºabhishekæŠ•ä¸Šä¸€ä¸ªèµæˆç¥¨ã€‚</p>
<h1 id="å¯¼å…¥éœ€è¦ç”¨åˆ°çš„åŒ…"><a href="#å¯¼å…¥éœ€è¦ç”¨åˆ°çš„åŒ…" class="headerlink" title="å¯¼å…¥éœ€è¦ç”¨åˆ°çš„åŒ…"></a>å¯¼å…¥éœ€è¦ç”¨åˆ°çš„åŒ…</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="comment"># tqdmç”¨æ¥è®°å½•notebookè®­ç»ƒçš„è¿›åº¦æ¡</span></span><br><span class="line"><span class="keyword">from</span> tqdm.autonotebook <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">import</span> tokenizers</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_linear_schedule_with_warmup</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">config</span>:</span></span><br><span class="line">    MAX_LEN = <span class="number">128</span></span><br><span class="line">    TRAIN_BATCH_SIZE = <span class="number">64</span></span><br><span class="line">    VALID_BATCH_SIZE = <span class="number">16</span></span><br><span class="line">    EPOCHS = <span class="number">6</span></span><br><span class="line">    ROBERTA_PATH = <span class="string">"../input/roberta-base/"</span></span><br><span class="line">    MODEL_PATH = <span class="string">"pytorch_model.bin"</span></span><br><span class="line">    TRAINING_FILE = <span class="string">"../input/tweet-train-folds/train_folds.csv"</span></span><br><span class="line">    TOKENIZER = tokenizers.ByteLevelBPETokenizer(</span><br><span class="line">    vocab_file=<span class="string">f"<span class="subst">&#123;ROBERTA_PATH&#125;</span>/vocab.json"</span>, </span><br><span class="line">    merges_file=<span class="string">f"<span class="subst">&#123;ROBERTA_PATH&#125;</span>/merges.txt"</span>, </span><br><span class="line">    lowercase=<span class="literal">True</span>,</span><br><span class="line">    add_prefix_space=<span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<h1 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_data</span><span class="params">(tweet, selected_text, sentiment, tokenizer, max_len)</span>:</span></span><br><span class="line">    tweet = <span class="string">" "</span> + <span class="string">" "</span>.join(str(tweet).split())</span><br><span class="line">    selected_text = <span class="string">" "</span> + <span class="string">" "</span>.join(str(selected_text).split())</span><br><span class="line"></span><br><span class="line">    len_st = len(selected_text) - <span class="number">1</span></span><br><span class="line">    idx0 = <span class="literal">None</span></span><br><span class="line">    idx1 = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ind <span class="keyword">in</span> (i <span class="keyword">for</span> i, e <span class="keyword">in</span> enumerate(tweet) <span class="keyword">if</span> e == selected_text[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">" "</span> + tweet[ind: ind+len_st] == selected_text:</span><br><span class="line">            idx0 = ind</span><br><span class="line">            idx1 = ind + len_st - <span class="number">1</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    char_targets = [<span class="number">0</span>] * len(tweet)</span><br><span class="line">    <span class="keyword">if</span> idx0 != <span class="literal">None</span> <span class="keyword">and</span> idx1 != <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">for</span> ct <span class="keyword">in</span> range(idx0, idx1 + <span class="number">1</span>):</span><br><span class="line">            char_targets[ct] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    tok_tweet = tokenizer.encode(tweet)</span><br><span class="line">    input_ids_orig = tok_tweet.ids</span><br><span class="line">    tweet_offsets = tok_tweet.offsets</span><br><span class="line">    </span><br><span class="line">    target_idx = []</span><br><span class="line">    <span class="keyword">for</span> j, (offset1, offset2) <span class="keyword">in</span> enumerate(tweet_offsets):</span><br><span class="line">        <span class="keyword">if</span> sum(char_targets[offset1: offset2]) &gt; <span class="number">0</span>:</span><br><span class="line">            target_idx.append(j)</span><br><span class="line">    </span><br><span class="line">    targets_start = target_idx[<span class="number">0</span>]</span><br><span class="line">    targets_end = target_idx[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    sentiment_id = &#123;</span><br><span class="line">        <span class="string">'positive'</span>: <span class="number">1313</span>,</span><br><span class="line">        <span class="string">'negative'</span>: <span class="number">2430</span>,</span><br><span class="line">        <span class="string">'neutral'</span>: <span class="number">7974</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    input_ids = [<span class="number">0</span>] + [sentiment_id[sentiment]] + [<span class="number">2</span>] + [<span class="number">2</span>] + input_ids_orig + [<span class="number">2</span>]</span><br><span class="line">    token_type_ids = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>] + [<span class="number">0</span>] * (len(input_ids_orig) + <span class="number">1</span>)</span><br><span class="line">    mask = [<span class="number">1</span>] * len(token_type_ids)</span><br><span class="line">    tweet_offsets = [(<span class="number">0</span>, <span class="number">0</span>)] * <span class="number">4</span> + tweet_offsets + [(<span class="number">0</span>, <span class="number">0</span>)]</span><br><span class="line">    targets_start += <span class="number">4</span></span><br><span class="line">    targets_end += <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    padding_length = max_len - len(input_ids)</span><br><span class="line">    <span class="keyword">if</span> padding_length &gt; <span class="number">0</span>:</span><br><span class="line">        input_ids = input_ids + ([<span class="number">1</span>] * padding_length)</span><br><span class="line">        mask = mask + ([<span class="number">0</span>] * padding_length)</span><br><span class="line">        token_type_ids = token_type_ids + ([<span class="number">0</span>] * padding_length)</span><br><span class="line">        tweet_offsets = tweet_offsets + ([(<span class="number">0</span>, <span class="number">0</span>)] * padding_length)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">'ids'</span>: input_ids,</span><br><span class="line">        <span class="string">'mask'</span>: mask,</span><br><span class="line">        <span class="string">'token_type_ids'</span>: token_type_ids,</span><br><span class="line">        <span class="string">'targets_start'</span>: targets_start,</span><br><span class="line">        <span class="string">'targets_end'</span>: targets_end,</span><br><span class="line">        <span class="string">'orig_tweet'</span>: tweet,</span><br><span class="line">        <span class="string">'orig_selected'</span>: selected_text,</span><br><span class="line">        <span class="string">'sentiment'</span>: sentiment,</span><br><span class="line">        <span class="string">'offsets'</span>: tweet_offsets</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h1 id="Data-loader"><a href="#Data-loader" class="headerlink" title="Data loader"></a>Data loader</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TweetDataset</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Dataset which stores the tweets and returns them as processed features</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tweet, sentiment, selected_text)</span>:</span></span><br><span class="line">        self.tweet = tweet</span><br><span class="line">        self.sentiment = sentiment</span><br><span class="line">        self.selected_text = selected_text</span><br><span class="line">        self.tokenizer = config.TOKENIZER</span><br><span class="line">        self.max_len = config.MAX_LEN</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.tweet)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, item)</span>:</span></span><br><span class="line">        data = process_data(</span><br><span class="line">            self.tweet[item], </span><br><span class="line">            self.selected_text[item], </span><br><span class="line">            self.sentiment[item],</span><br><span class="line">            self.tokenizer,</span><br><span class="line">            self.max_len</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Return the processed data where the lists are converted to `torch.tensor`s</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">'ids'</span>: torch.tensor(data[<span class="string">"ids"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'mask'</span>: torch.tensor(data[<span class="string">"mask"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'token_type_ids'</span>: torch.tensor(data[<span class="string">"token_type_ids"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'targets_start'</span>: torch.tensor(data[<span class="string">"targets_start"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'targets_end'</span>: torch.tensor(data[<span class="string">"targets_end"</span>], dtype=torch.long),</span><br><span class="line">            <span class="string">'orig_tweet'</span>: data[<span class="string">"orig_tweet"</span>],</span><br><span class="line">            <span class="string">'orig_selected'</span>: data[<span class="string">"orig_selected"</span>],</span><br><span class="line">            <span class="string">'sentiment'</span>: data[<span class="string">"sentiment"</span>],</span><br><span class="line">            <span class="string">'offsets'</span>: torch.tensor(data[<span class="string">"offsets"</span>], dtype=torch.long)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<h1 id="æ¨¡å‹å®šä¹‰"><a href="#æ¨¡å‹å®šä¹‰" class="headerlink" title="æ¨¡å‹å®šä¹‰"></a>æ¨¡å‹å®šä¹‰</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TweetModel</span><span class="params">(transformers.BertPreTrainedModel)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, conf)</span>:</span></span><br><span class="line">        super(TweetModel, self).__init__(conf)</span><br><span class="line">        self.roberta = transformers.RobertaModel.from_pretrained(config.ROBERTA_PATH, config=conf)</span><br><span class="line">        self.drop_out = nn.Dropout(<span class="number">0.1</span>)</span><br><span class="line">        self.l_1 = nn.Linear(<span class="number">768</span> * <span class="number">2</span>, <span class="number">400</span>)</span><br><span class="line">        self.l0 = nn.Linear(<span class="number">400</span>, <span class="number">2</span>)</span><br><span class="line">        torch.nn.init.normal_(self.l0.weight, std=<span class="number">0.02</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, ids, mask, token_type_ids)</span>:</span></span><br><span class="line">        _, _, out = self.roberta(</span><br><span class="line">            ids,</span><br><span class="line">            attention_mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        out = torch.cat((out[<span class="number">-1</span>], out[<span class="number">-2</span>]), dim=<span class="number">-1</span>)</span><br><span class="line">        out = self.drop_out(out)</span><br><span class="line">        logits = self.l_1(out)</span><br><span class="line">        logits = self.l0(logits)</span><br><span class="line"></span><br><span class="line">        start_logits, end_logits = logits.split(<span class="number">1</span>, dim=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        start_logits = start_logits.squeeze(<span class="number">-1</span>)</span><br><span class="line">        end_logits = end_logits.squeeze(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> start_logits, end_logits</span><br></pre></td></tr></table></figure>
<h1 id="è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼ˆoptional-å–å†³äºä»»åŠ¡ï¼‰"><a href="#è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼ˆoptional-å–å†³äºä»»åŠ¡ï¼‰" class="headerlink" title="è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼ˆoptional,å–å†³äºä»»åŠ¡ï¼‰"></a>è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼ˆoptional,å–å†³äºä»»åŠ¡ï¼‰</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_fn</span><span class="params">(start_logits, end_logits, start_positions, end_positions)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Return the sum of the cross entropy losses for both the start and end logits</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    loss_fct = nn.CrossEntropyLoss()</span><br><span class="line">    start_loss = loss_fct(start_logits, start_positions)</span><br><span class="line">    end_loss = loss_fct(end_logits, end_positions)</span><br><span class="line">    total_loss = (start_loss + end_loss)</span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br></pre></td></tr></table></figure>
<h1 id="Training-Function"><a href="#Training-Function" class="headerlink" title="Training Function"></a>Training Function</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fn</span><span class="params">(data_loader, model, optimizer, device, scheduler=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Trains the bert model on the twitter data</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Set model to training mode (dropout + sampled batchnorm is activated)</span></span><br><span class="line">    model.train()</span><br><span class="line">    losses = utils.AverageMeter()</span><br><span class="line">    jaccards = utils.AverageMeter()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set tqdm to add loading screen and set the length</span></span><br><span class="line">    tk0 = tqdm(data_loader, total=len(data_loader))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Train the model on each batch</span></span><br><span class="line">    <span class="keyword">for</span> bi, d <span class="keyword">in</span> enumerate(tk0):</span><br><span class="line"></span><br><span class="line">        ids = d[<span class="string">"ids"</span>]</span><br><span class="line">        token_type_ids = d[<span class="string">"token_type_ids"</span>]</span><br><span class="line">        mask = d[<span class="string">"mask"</span>]</span><br><span class="line">        targets_start = d[<span class="string">"targets_start"</span>]</span><br><span class="line">        targets_end = d[<span class="string">"targets_end"</span>]</span><br><span class="line">        sentiment = d[<span class="string">"sentiment"</span>]</span><br><span class="line">        orig_selected = d[<span class="string">"orig_selected"</span>]</span><br><span class="line">        orig_tweet = d[<span class="string">"orig_tweet"</span>]</span><br><span class="line">        targets_start = d[<span class="string">"targets_start"</span>]</span><br><span class="line">        targets_end = d[<span class="string">"targets_end"</span>]</span><br><span class="line">        offsets = d[<span class="string">"offsets"</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Move ids, masks, and targets to gpu while setting as torch.long</span></span><br><span class="line">        ids = ids.to(device, dtype=torch.long)</span><br><span class="line">        token_type_ids = token_type_ids.to(device, dtype=torch.long)</span><br><span class="line">        mask = mask.to(device, dtype=torch.long)</span><br><span class="line">        targets_start = targets_start.to(device, dtype=torch.long)</span><br><span class="line">        targets_end = targets_end.to(device, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Reset gradients</span></span><br><span class="line">        model.zero_grad()</span><br><span class="line">        <span class="comment"># Use ids, masks, and token types as input to the model</span></span><br><span class="line">        <span class="comment"># Predict logits for each of the input tokens for each batch</span></span><br><span class="line">        outputs_start, outputs_end = model(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids,</span><br><span class="line">        ) <span class="comment"># (bs x SL), (bs x SL)</span></span><br><span class="line">        <span class="comment"># Calculate batch loss based on CrossEntropy</span></span><br><span class="line">        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)</span><br><span class="line">        <span class="comment"># Calculate gradients based on loss</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># Adjust weights based on calculated gradients</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># Update scheduler</span></span><br><span class="line">        scheduler.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply softmax to the start and end logits</span></span><br><span class="line">        <span class="comment"># This squeezes each of the logits in a sequence to a value between 0 and 1, while ensuring that they sum to 1</span></span><br><span class="line">        <span class="comment"># This is similar to the characteristics of "probabilities"</span></span><br><span class="line">        outputs_start = torch.softmax(outputs_start, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">        outputs_end = torch.softmax(outputs_end, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculate the jaccard score based on the predictions for this batch</span></span><br><span class="line">        jaccard_scores = []</span><br><span class="line">        <span class="keyword">for</span> px, tweet <span class="keyword">in</span> enumerate(orig_tweet):</span><br><span class="line">            selected_tweet = orig_selected[px]</span><br><span class="line">            tweet_sentiment = sentiment[px]</span><br><span class="line">            jaccard_score, _ = calculate_jaccard_score(</span><br><span class="line">                original_tweet=tweet, <span class="comment"># Full text of the px'th tweet in the batch</span></span><br><span class="line">                target_string=selected_tweet, <span class="comment"># Span containing the specified sentiment for the px'th tweet in the batch</span></span><br><span class="line">                sentiment_val=tweet_sentiment, <span class="comment"># Sentiment of the px'th tweet in the batch</span></span><br><span class="line">                idx_start=np.argmax(outputs_start[px, :]), <span class="comment"># Predicted start index for the px'th tweet in the batch</span></span><br><span class="line">                idx_end=np.argmax(outputs_end[px, :]), <span class="comment"># Predicted end index for the px'th tweet in the batch</span></span><br><span class="line">                offsets=offsets[px] <span class="comment"># Offsets for each of the tokens for the px'th tweet in the batch</span></span><br><span class="line">            )</span><br><span class="line">            jaccard_scores.append(jaccard_score)</span><br><span class="line">        <span class="comment"># Update the jaccard score and loss</span></span><br><span class="line">        <span class="comment"># For details, refer to `AverageMeter` in https://www.kaggle.com/abhishek/utils</span></span><br><span class="line">        jaccards.update(np.mean(jaccard_scores), ids.size(<span class="number">0</span>))</span><br><span class="line">        losses.update(loss.item(), ids.size(<span class="number">0</span>))</span><br><span class="line">        <span class="comment"># Print the average loss and jaccard score at the end of each batch</span></span><br><span class="line">        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)</span><br></pre></td></tr></table></figure>
<h1 id="Evaluation-Functions"><a href="#Evaluation-Functions" class="headerlink" title="Evaluation Functions"></a>Evaluation Functions</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_jaccard_score</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    original_tweet, </span></span></span><br><span class="line"><span class="function"><span class="params">    target_string, </span></span></span><br><span class="line"><span class="function"><span class="params">    sentiment_val, </span></span></span><br><span class="line"><span class="function"><span class="params">    idx_start, </span></span></span><br><span class="line"><span class="function"><span class="params">    idx_end, </span></span></span><br><span class="line"><span class="function"><span class="params">    offsets,</span></span></span><br><span class="line"><span class="function"><span class="params">    verbose=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Calculate the jaccard score from the predicted span and the actual span for a batch of tweets</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># A span's start index has to be greater than or equal to the end index</span></span><br><span class="line">    <span class="comment"># If this doesn't hold, the start index is set to equal the end index (the span is a single token)</span></span><br><span class="line">    <span class="keyword">if</span> idx_end &lt; idx_start:</span><br><span class="line">        idx_end = idx_start</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Combine into a string the tokens that belong to the predicted span</span></span><br><span class="line">    filtered_output  = <span class="string">""</span></span><br><span class="line">    <span class="keyword">for</span> ix <span class="keyword">in</span> range(idx_start, idx_end + <span class="number">1</span>):</span><br><span class="line">        filtered_output += original_tweet[offsets[ix][<span class="number">0</span>]: offsets[ix][<span class="number">1</span>]]</span><br><span class="line">        <span class="comment"># If the token is not the last token in the tweet, and the ending offset of the current token is less</span></span><br><span class="line">        <span class="comment"># than the beginning offset of the following token, add a space.</span></span><br><span class="line">        <span class="comment"># Basically, add a space when the next token (word piece) corresponds to a new word</span></span><br><span class="line">        <span class="keyword">if</span> (ix+<span class="number">1</span>) &lt; len(offsets) <span class="keyword">and</span> offsets[ix][<span class="number">1</span>] &lt; offsets[ix+<span class="number">1</span>][<span class="number">0</span>]:</span><br><span class="line">            filtered_output += <span class="string">" "</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set the predicted output as the original tweet when the tweet's sentiment is "neutral", or the tweet only contains one word</span></span><br><span class="line">    <span class="keyword">if</span> sentiment_val == <span class="string">"neutral"</span> <span class="keyword">or</span> len(original_tweet.split()) &lt; <span class="number">2</span>:</span><br><span class="line">        filtered_output = original_tweet</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the jaccard score between the predicted span, and the actual span</span></span><br><span class="line">    <span class="comment"># The IOU (intersection over union) approach is detailed in the utils module's `jaccard` function:</span></span><br><span class="line">    <span class="comment"># https://www.kaggle.com/abhishek/utils</span></span><br><span class="line">    jac = utils.jaccard(target_string.strip(), filtered_output.strip())</span><br><span class="line">    <span class="keyword">return</span> jac, filtered_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_fn</span><span class="params">(data_loader, model, device)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Evaluation function to predict on the test set</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Set model to evaluation mode</span></span><br><span class="line">    <span class="comment"># I.e., turn off dropout and set batchnorm to use overall mean and variance (from training), rather than batch level mean and variance</span></span><br><span class="line">    <span class="comment"># Reference: https://github.com/pytorch/pytorch/issues/5406</span></span><br><span class="line">    model.eval()</span><br><span class="line">    losses = utils.AverageMeter()</span><br><span class="line">    jaccards = utils.AverageMeter()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Turns off gradient calculations (https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch)</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        tk0 = tqdm(data_loader, total=len(data_loader))</span><br><span class="line">        <span class="comment"># Make predictions and calculate loss / jaccard score for each batch</span></span><br><span class="line">        <span class="keyword">for</span> bi, d <span class="keyword">in</span> enumerate(tk0):</span><br><span class="line">            ids = d[<span class="string">"ids"</span>]</span><br><span class="line">            token_type_ids = d[<span class="string">"token_type_ids"</span>]</span><br><span class="line">            mask = d[<span class="string">"mask"</span>]</span><br><span class="line">            sentiment = d[<span class="string">"sentiment"</span>]</span><br><span class="line">            orig_selected = d[<span class="string">"orig_selected"</span>]</span><br><span class="line">            orig_tweet = d[<span class="string">"orig_tweet"</span>]</span><br><span class="line">            targets_start = d[<span class="string">"targets_start"</span>]</span><br><span class="line">            targets_end = d[<span class="string">"targets_end"</span>]</span><br><span class="line">            offsets = d[<span class="string">"offsets"</span>].numpy()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Move tensors to GPU for faster matrix calculations</span></span><br><span class="line">            ids = ids.to(device, dtype=torch.long)</span><br><span class="line">            token_type_ids = token_type_ids.to(device, dtype=torch.long)</span><br><span class="line">            mask = mask.to(device, dtype=torch.long)</span><br><span class="line">            targets_start = targets_start.to(device, dtype=torch.long)</span><br><span class="line">            targets_end = targets_end.to(device, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Predict logits for start and end indexes</span></span><br><span class="line">            outputs_start, outputs_end = model(</span><br><span class="line">                ids=ids,</span><br><span class="line">                mask=mask,</span><br><span class="line">                token_type_ids=token_type_ids</span><br><span class="line">            )</span><br><span class="line">            <span class="comment"># Calculate loss for the batch</span></span><br><span class="line">            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)</span><br><span class="line">            <span class="comment"># Apply softmax to the predicted logits for the start and end indexes</span></span><br><span class="line">            <span class="comment"># This converts the "logits" to "probability-like" scores</span></span><br><span class="line">            outputs_start = torch.softmax(outputs_start, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">            outputs_end = torch.softmax(outputs_end, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">            <span class="comment"># Calculate jaccard scores for each tweet in the batch</span></span><br><span class="line">            jaccard_scores = []</span><br><span class="line">            <span class="keyword">for</span> px, tweet <span class="keyword">in</span> enumerate(orig_tweet):</span><br><span class="line">                selected_tweet = orig_selected[px]</span><br><span class="line">                tweet_sentiment = sentiment[px]</span><br><span class="line">                jaccard_score, _ = calculate_jaccard_score(</span><br><span class="line">                    original_tweet=tweet,</span><br><span class="line">                    target_string=selected_tweet,</span><br><span class="line">                    sentiment_val=tweet_sentiment,</span><br><span class="line">                    idx_start=np.argmax(outputs_start[px, :]),</span><br><span class="line">                    idx_end=np.argmax(outputs_end[px, :]),</span><br><span class="line">                    offsets=offsets[px]</span><br><span class="line">                )</span><br><span class="line">                jaccard_scores.append(jaccard_score)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Update running jaccard score and loss</span></span><br><span class="line">            jaccards.update(np.mean(jaccard_scores), ids.size(<span class="number">0</span>))</span><br><span class="line">            losses.update(loss.item(), ids.size(<span class="number">0</span>))</span><br><span class="line">            <span class="comment"># Print the running average loss and jaccard score</span></span><br><span class="line">            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">f"Jaccard = <span class="subst">&#123;jaccards.avg&#125;</span>"</span>)</span><br><span class="line">    <span class="keyword">return</span> jaccards.avg</span><br></pre></td></tr></table></figure>
<h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(fold)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Train model for a speciied fold</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Read training csv</span></span><br><span class="line">    dfx = pd.read_csv(config.TRAINING_FILE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set train validation set split</span></span><br><span class="line">    df_train = dfx[dfx.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = dfx[dfx.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Instantiate TweetDataset with training data</span></span><br><span class="line">    train_dataset = TweetDataset(</span><br><span class="line">        tweet=df_train.text.values,</span><br><span class="line">        sentiment=df_train.sentiment.values,</span><br><span class="line">        selected_text=df_train.selected_text.values</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Instantiate DataLoader with `train_dataset`</span></span><br><span class="line">    <span class="comment"># This is a generator that yields the dataset in batches</span></span><br><span class="line">    train_data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        train_dataset,</span><br><span class="line">        batch_size=config.TRAIN_BATCH_SIZE,</span><br><span class="line">        num_workers=<span class="number">4</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Instantiate TweetDataset with validation data</span></span><br><span class="line">    valid_dataset = TweetDataset(</span><br><span class="line">        tweet=df_valid.text.values,</span><br><span class="line">        sentiment=df_valid.sentiment.values,</span><br><span class="line">        selected_text=df_valid.selected_text.values</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Instantiate DataLoader with `valid_dataset`</span></span><br><span class="line">    valid_data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        valid_dataset,</span><br><span class="line">        batch_size=config.VALID_BATCH_SIZE,</span><br><span class="line">        num_workers=<span class="number">2</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set device as `cuda` (GPU)</span></span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">    <span class="comment"># Load pretrained BERT (bert-base-uncased)</span></span><br><span class="line">    model_config = transformers.RobertaConfig.from_pretrained(config.ROBERTA_PATH)</span><br><span class="line">    <span class="comment"># Output hidden states</span></span><br><span class="line">    <span class="comment"># This is important to set since we want to concatenate the hidden states from the last 2 BERT layers</span></span><br><span class="line">    model_config.output_hidden_states = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># Instantiate our model with `model_config`</span></span><br><span class="line">    model = TweetModel(conf=model_config)</span><br><span class="line">    <span class="comment"># Move the model to the GPU</span></span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the number of training steps</span></span><br><span class="line">    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)</span><br><span class="line">    <span class="comment"># Get the list of named parameters</span></span><br><span class="line">    param_optimizer = list(model.named_parameters())</span><br><span class="line">    <span class="comment"># Specify parameters where weight decay shouldn't be applied</span></span><br><span class="line">    no_decay = [<span class="string">"bias"</span>, <span class="string">"LayerNorm.bias"</span>, <span class="string">"LayerNorm.weight"</span>]</span><br><span class="line">    <span class="comment"># Define two sets of parameters: those with weight decay, and those without</span></span><br><span class="line">    optimizer_parameters = [</span><br><span class="line">        &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> param_optimizer <span class="keyword">if</span> <span class="keyword">not</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.001</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> param_optimizer <span class="keyword">if</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.0</span>&#125;,</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># Instantiate AdamW optimizer with our two sets of parameters, and a learning rate of 3e-5</span></span><br><span class="line">    optimizer = AdamW(optimizer_parameters, lr=<span class="number">3e-5</span>)</span><br><span class="line">    <span class="comment"># Create a scheduler to set the learning rate at each training step</span></span><br><span class="line">    <span class="comment"># "Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period." (https://pytorch.org/docs/stable/optim.html)</span></span><br><span class="line">    <span class="comment"># Since num_warmup_steps = 0, the learning rate starts at 3e-5, and then linearly decreases at each training step</span></span><br><span class="line">    scheduler = get_linear_schedule_with_warmup(</span><br><span class="line">        optimizer, </span><br><span class="line">        num_warmup_steps=<span class="number">0</span>, </span><br><span class="line">        num_training_steps=num_train_steps</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Apply early stopping with patience of 2</span></span><br><span class="line">    <span class="comment"># This means to stop training new epochs when 2 rounds have passed without any improvement</span></span><br><span class="line">    es = utils.EarlyStopping(patience=<span class="number">2</span>, mode=<span class="string">"max"</span>)</span><br><span class="line">    print(<span class="string">f"Training is Starting for fold=<span class="subst">&#123;fold&#125;</span>"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># I'm training only for 3 epochs even though I specified 5!!!</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)</span><br><span class="line">        jaccard = eval_fn(valid_data_loader, model, device)</span><br><span class="line">        print(<span class="string">f"Jaccard Score = <span class="subst">&#123;jaccard&#125;</span>"</span>)</span><br><span class="line">        es(jaccard, model, model_path=<span class="string">f"model_<span class="subst">&#123;fold&#125;</span>.bin"</span>)</span><br><span class="line">        <span class="keyword">if</span> es.early_stop:</span><br><span class="line">            print(<span class="string">"Early stopping"</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fold=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Do-the-evaluation-on-test-data"><a href="#Do-the-evaluation-on-test-data" class="headerlink" title="Do the evaluation on test data"></a>Do the evaluation on test data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_test = pd.read_csv(<span class="string">"../input/tweet-sentiment-extraction/test.csv"</span>)</span><br><span class="line">df_test.loc[:, <span class="string">"selected_text"</span>] = df_test.text.values</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_test</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>textID</th>
      <th>text</th>
      <th>sentiment</th>
      <th>selected_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>f87dea47db</td>
      <td>Last session of the day  http://twitpic.com/67ezh</td>
      <td>neutral</td>
      <td>Last session of the day  http://twitpic.com/67ezh</td>
    </tr>
    <tr>
      <th>1</th>
      <td>96d74cb729</td>
      <td>Shanghai is also really exciting (precisely -...</td>
      <td>positive</td>
      <td>Shanghai is also really exciting (precisely -...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>eee518ae67</td>
      <td>Recession hit Veronique Branquinho, she has to...</td>
      <td>negative</td>
      <td>Recession hit Veronique Branquinho, she has to...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>01082688c6</td>
      <td>happy bday!</td>
      <td>positive</td>
      <td>happy bday!</td>
    </tr>
    <tr>
      <th>4</th>
      <td>33987a8ee5</td>
      <td>http://twitpic.com/4w75p - I like it!!</td>
      <td>positive</td>
      <td>http://twitpic.com/4w75p - I like it!!</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3529</th>
      <td>e5f0e6ef4b</td>
      <td>its at 3 am, im very tired but i can`t sleep  ...</td>
      <td>negative</td>
      <td>its at 3 am, im very tired but i can`t sleep  ...</td>
    </tr>
    <tr>
      <th>3530</th>
      <td>416863ce47</td>
      <td>All alone in this old house again.  Thanks for...</td>
      <td>positive</td>
      <td>All alone in this old house again.  Thanks for...</td>
    </tr>
    <tr>
      <th>3531</th>
      <td>6332da480c</td>
      <td>I know what you mean. My little dog is sinkin...</td>
      <td>negative</td>
      <td>I know what you mean. My little dog is sinkin...</td>
    </tr>
    <tr>
      <th>3532</th>
      <td>df1baec676</td>
      <td>_sutra what is your next youtube video gonna b...</td>
      <td>positive</td>
      <td>_sutra what is your next youtube video gonna b...</td>
    </tr>
    <tr>
      <th>3533</th>
      <td>469e15c5a8</td>
      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>
      <td>positive</td>
      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>
    </tr>
  </tbody>
</table>
<p>3534 rows Ã— 4 columns</p>

</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">model_config = transformers.RobertaConfig.from_pretrained(config.ROBERTA_PATH)</span><br><span class="line">model_config.output_hidden_states = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load each of the five trained models and move to GPU</span></span><br><span class="line">model1 = TweetModel(conf=model_config)</span><br><span class="line">model1.to(device)</span><br><span class="line">model1.load_state_dict(torch.load(<span class="string">"model_0.bin"</span>))</span><br><span class="line">model1.eval()</span><br><span class="line"></span><br><span class="line">model2 = TweetModel(conf=model_config)</span><br><span class="line">model2.to(device)</span><br><span class="line">model2.load_state_dict(torch.load(<span class="string">"model_1.bin"</span>))</span><br><span class="line">model2.eval()</span><br><span class="line"></span><br><span class="line">model3 = TweetModel(conf=model_config)</span><br><span class="line">model3.to(device)</span><br><span class="line">model3.load_state_dict(torch.load(<span class="string">"model_2.bin"</span>))</span><br><span class="line">model3.eval()</span><br><span class="line"></span><br><span class="line">model4 = TweetModel(conf=model_config)</span><br><span class="line">model4.to(device)</span><br><span class="line">model4.load_state_dict(torch.load(<span class="string">"model_3.bin"</span>))</span><br><span class="line">model4.eval()</span><br><span class="line"></span><br><span class="line">model5 = TweetModel(conf=model_config)</span><br><span class="line">model5.to(device)</span><br><span class="line">model5.load_state_dict(torch.load(<span class="string">"model_4.bin"</span>))</span><br><span class="line">model5.eval()</span><br></pre></td></tr></table></figure>
<pre><code>TweetModel(
  (roberta): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (drop_out): Dropout(p=0.1, inplace=False)
  (l_1): Linear(in_features=1536, out_features=400, bias=True)
  (l0): Linear(in_features=400, out_features=2, bias=True)
)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">final_output = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate TweetDataset with the test data</span></span><br><span class="line">test_dataset = TweetDataset(</span><br><span class="line">        tweet=df_test.text.values,</span><br><span class="line">        sentiment=df_test.sentiment.values,</span><br><span class="line">        selected_text=df_test.selected_text.values</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate DataLoader with `test_dataset`</span></span><br><span class="line">data_loader = torch.utils.data.DataLoader(</span><br><span class="line">    test_dataset,</span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    batch_size=config.VALID_BATCH_SIZE,</span><br><span class="line">    num_workers=<span class="number">1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn of gradient calculations</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    tk0 = tqdm(data_loader, total=len(data_loader))</span><br><span class="line">    <span class="comment"># Predict the span containing the sentiment for each batch</span></span><br><span class="line">    <span class="keyword">for</span> bi, d <span class="keyword">in</span> enumerate(tk0):</span><br><span class="line">        ids = d[<span class="string">"ids"</span>]</span><br><span class="line">        token_type_ids = d[<span class="string">"token_type_ids"</span>]</span><br><span class="line">        mask = d[<span class="string">"mask"</span>]</span><br><span class="line">        sentiment = d[<span class="string">"sentiment"</span>]</span><br><span class="line">        orig_selected = d[<span class="string">"orig_selected"</span>]</span><br><span class="line">        orig_tweet = d[<span class="string">"orig_tweet"</span>]</span><br><span class="line">        targets_start = d[<span class="string">"targets_start"</span>]</span><br><span class="line">        targets_end = d[<span class="string">"targets_end"</span>]</span><br><span class="line">        offsets = d[<span class="string">"offsets"</span>].numpy()</span><br><span class="line"></span><br><span class="line">        ids = ids.to(device, dtype=torch.long)</span><br><span class="line">        token_type_ids = token_type_ids.to(device, dtype=torch.long)</span><br><span class="line">        mask = mask.to(device, dtype=torch.long)</span><br><span class="line">        targets_start = targets_start.to(device, dtype=torch.long)</span><br><span class="line">        targets_end = targets_end.to(device, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Predict start and end logits for each of the five models</span></span><br><span class="line">        outputs_start1, outputs_end1 = model1(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        outputs_start2, outputs_end2 = model2(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        outputs_start3, outputs_end3 = model3(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        outputs_start4, outputs_end4 = model4(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        outputs_start5, outputs_end5 = model5(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get the average start and end logits across the five models and use these as predictions</span></span><br><span class="line">        <span class="comment"># This is a form of "ensembling"</span></span><br><span class="line">        outputs_start = (</span><br><span class="line">            outputs_start1 </span><br><span class="line">            + outputs_start2 </span><br><span class="line">            + outputs_start3 </span><br><span class="line">            + outputs_start4 </span><br><span class="line">            + outputs_start5</span><br><span class="line">        ) / <span class="number">5</span></span><br><span class="line">        outputs_end = (</span><br><span class="line">            outputs_end1 </span><br><span class="line">            + outputs_end2 </span><br><span class="line">            + outputs_end3 </span><br><span class="line">            + outputs_end4 </span><br><span class="line">            + outputs_end5</span><br><span class="line">        ) / <span class="number">5</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply softmax to the predicted start and end logits</span></span><br><span class="line">        outputs_start = torch.softmax(outputs_start, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">        outputs_end = torch.softmax(outputs_end, dim=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Convert the start and end scores to actual predicted spans (in string form)</span></span><br><span class="line">        <span class="keyword">for</span> px, tweet <span class="keyword">in</span> enumerate(orig_tweet):</span><br><span class="line">            selected_tweet = orig_selected[px]</span><br><span class="line">            tweet_sentiment = sentiment[px]</span><br><span class="line">            _, output_sentence = calculate_jaccard_score(</span><br><span class="line">                original_tweet=tweet,</span><br><span class="line">                target_string=selected_tweet,</span><br><span class="line">                sentiment_val=tweet_sentiment,</span><br><span class="line">                idx_start=np.argmax(outputs_start[px, :]),</span><br><span class="line">                idx_end=np.argmax(outputs_end[px, :]),</span><br><span class="line">                offsets=offsets[px]</span><br><span class="line">            )</span><br><span class="line">            final_output.append(output_sentence)</span><br></pre></td></tr></table></figure>
<pre><code>HBox(children=(FloatProgress(value=0.0, max=221.0), HTML(value=&#39;&#39;)))
</code></pre><p>â€‹<br>â€‹    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># post-process trick:</span></span><br><span class="line"><span class="comment"># Note: This trick comes from: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/140942</span></span><br><span class="line"><span class="comment"># When the LB resets, this trick won't help</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post_process</span><span class="params">(selected)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">" "</span>.join(set(selected.lower().split()))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sample = pd.read_csv(<span class="string">"../input/tweet-sentiment-extraction/sample_submission.csv"</span>)</span><br><span class="line">sample.loc[:, <span class="string">'selected_text'</span>] = final_output</span><br><span class="line">sample.selected_text = sample.selected_text.map(post_process)</span><br><span class="line">sample.to_csv(<span class="string">"submission.csv"</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>textID</th>
      <th>selected_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>f87dea47db</td>
      <td>http://twitpic.com/67ezh the of day session last</td>
    </tr>
    <tr>
      <th>1</th>
      <td>96d74cb729</td>
      <td>exciting</td>
    </tr>
    <tr>
      <th>2</th>
      <td>eee518ae67</td>
      <td>such shame! a</td>
    </tr>
    <tr>
      <th>3</th>
      <td>01082688c6</td>
      <td>happy bday!</td>
    </tr>
    <tr>
      <th>4</th>
      <td>33987a8ee5</td>
      <td>i like</td>
    </tr>
  </tbody>
</table>

</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line">source_DF = inspect.getsource(utils)</span><br><span class="line">print(source_DF)</span><br></pre></td></tr></table></figure>
<pre><code>import numpy as np
import torch
</code></pre><p>â€‹    </p>
<pre><code>class AverageMeter:
    &quot;&quot;&quot;
    Computes and stores the average and current value
    &quot;&quot;&quot;
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count
</code></pre><p>â€‹    </p>
<pre><code>class EarlyStopping:
    def __init__(self, patience=7, mode=&quot;max&quot;, delta=0.001):
        self.patience = patience
        self.counter = 0
        self.mode = mode
        self.best_score = None
        self.early_stop = False
        self.delta = delta
        if self.mode == &quot;min&quot;:
            self.val_score = np.Inf
        else:
            self.val_score = -np.Inf

    def __call__(self, epoch_score, model, model_path):

        if self.mode == &quot;min&quot;:
            score = -1.0 * epoch_score
        else:
            score = np.copy(epoch_score)

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(epoch_score, model, model_path)
        elif score &lt; self.best_score + self.delta:
            self.counter += 1
            print(&#39;EarlyStopping counter: {} out of {}&#39;.format(self.counter, self.patience))
            if self.counter &gt;= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(epoch_score, model, model_path)
            self.counter = 0

    def save_checkpoint(self, epoch_score, model, model_path):
        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:
            print(&#39;Validation score improved ({} --&gt; {}). Saving model!&#39;.format(self.val_score, epoch_score))
            torch.save(model.state_dict(), model_path)
        self.val_score = epoch_score
</code></pre><p>â€‹    </p>
<pre><code>def jaccard(str1, str2): 
    a = set(str1.lower().split()) 
    b = set(str2.lower().split())
    c = a.intersection(b)
    return float(len(c)) / (len(a) + len(b) - len(c))
</code></pre><p>â€‹    </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://dxzmpk.github.io/2020/04/22/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80-%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E4%B8%A4%E4%B8%AA%E5%B7%A5%E5%85%B7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="è‘£é›„">
      <meta itemprop="description" content="Learning in Harbin Institute of Technology">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="è‘£é›„å†™å­—çš„åœ°æ–¹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/22/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80-%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E4%B8%A4%E4%B8%AA%E5%B7%A5%E5%85%B7/" class="post-title-link" itemprop="url">ç®—æ³•è®¾è®¡åŸºç¡€-æœ€é‡è¦çš„ä¸¤ä¸ªå·¥å…·</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">å‘è¡¨äº</span>

              <time title="åˆ›å»ºæ—¶é—´ï¼š2020-04-22 15:02:12" itemprop="dateCreated datePublished" datetime="2020-04-22T15:02:12+08:00">2020-04-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-04-23 09:00:46" itemprop="dateModified" datetime="2020-04-23T09:00:46+08:00">2020-04-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/algorithms/" itemprop="url" rel="index"><span itemprop="name">algorithms</span></a>
                </span>
            </span>

          
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="ä¸¤ä¸ªåŸºç¡€"><a href="#ä¸¤ä¸ªåŸºç¡€" class="headerlink" title="ä¸¤ä¸ªåŸºç¡€"></a>ä¸¤ä¸ªåŸºç¡€</h3><ol>
<li><p>ç®—æ³•è®¾è®¡ä¸­çš„ä¸€é¡¹é‡è¦çš„æŠ€æœ¯æ˜¯ç¼©å°å…è®¸çš„å®ä¾‹çš„é›†åˆï¼Œç›´åˆ°æ‰¾åˆ°æ­£ç¡®æœ‰æ•ˆçš„ç®—æ³•ä¸ºæ­¢ã€‚</p>
</li>
<li><p>è¦åˆ©ç”¨å¥½å·²æœ‰çš„ç®—æ³•ï¼Œæ‚¨å¿…é¡»å­¦ä¼šåŸºæœ¬è¿‡ç¨‹ä¸­çš„â€œæŠ½è±¡åœ°â€æè¿°é—®é¢˜ã€‚æ ¹æ®å®šä¹‰å¥½çš„ç»“æ„å’Œç®—æ³•å¯¹åº”ç”¨ç¨‹åºè¿›è¡Œå»ºæ¨¡æ˜¯å®ç°è§£å†³æ–¹æ¡ˆçš„æœ€é‡è¦çš„ä¸€æ­¥ã€‚</p>
</li>
</ol>
<h3 id="RAM-å’Œ-å¤§O"><a href="#RAM-å’Œ-å¤§O" class="headerlink" title="RAM å’Œ å¤§O"></a>RAM å’Œ å¤§O</h3><ol>
<li><p>RAMè®¡ç®—æ¨¡å‹</p>
<p>å°†æœºå™¨æŠ½è±¡ä¸ºä¸€ä¸ªç®€å•çš„æœºå™¨ï¼Œåœ¨è¿™ä¸ªæœºå™¨ä¸Šè¿›è¡Œè®¡ç®—ï¼š</p>
<ul>
<li>æ¯ä¸ªç®€å•çš„æ“ä½œï¼ˆ+ï¼Œ*ï¼Œ-ï¼Œ=ï¼Œifï¼Œcallï¼‰åªéœ€ä¸€ä¸ªæ—¶é—´æ­¥ã€‚</li>
<li>å¾ªç¯å’Œå­ä¾‹ç¨‹ä¸è¢«è§†ä¸ºç®€å•æ“ä½œ</li>
<li>æ¯æ¬¡å†…å­˜è®¿é—®ä»…éœ€ä¸€ä¸ªæ—¶é—´æ­¥é•¿ï¼Œè€Œæ— éœ€æ³¨æ„ç¼“å­˜æˆ–ç£ç›˜ä¸­çš„å†…å®¹</li>
</ul>
</li>
<li><p>å¤§O</p>
<p>è¿™äº›å¤æ‚æ€§ä¸­çš„æ¯ä¸€ä¸ªéƒ½å®šä¹‰äº†ä¸€ä¸ªæ•°å­—å‡½æ•°ï¼Œè¡¨ç¤ºæ—¶é—´ä¸é—®é¢˜å¤§å°çš„å…³ç³»ã€‚ä½†æ˜¯æ—¶é—´ä¸Šçš„å¤æ‚æ€§æ˜¯å¦‚æ­¤å¤æ‚ï¼Œä»¥è‡³äºæˆ‘ä»¬å¿…é¡»ç®€åŒ–å®ƒä»¬ä»¥å®ç°åˆ©ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨å¤§Oç¬¦å·</p>
<p>é¦–å…ˆï¼Œè¦ç²¾ç¡®è®¡ç®—å¤æ‚åº¦éå¸¸å›°éš¾ï¼Œå› ä¸ºå®ƒå€¾å‘äºï¼š</p>
</li>
</ol>
<ul>
<li><p>å˜åŒ–å¾ˆå¤§ï¼Œä¸ç¨³å®š</p>
</li>
<li><p>éœ€è¦å¤ªå¤šç»†èŠ‚æ‰èƒ½ç²¾ç¡®æŒ‡å®šã€‚å› ä¸ºè®¡ç®—æœ€åæƒ…å†µä¸‹æ‰§è¡Œçš„RAMæŒ‡ä»¤çš„ç¡®åˆ‡æ•°é‡éœ€è¦æŠŠæ•´ä¸ªè®¡ç®—æœºç¨‹åºçš„ç»†èŠ‚è€ƒè™‘è¿›æ¥ã€‚</p>
<p> å¤§Oç¬¦å·ä¼šç²¾ç¡®åˆ°ä¸å½±å“æˆ‘ä»¬ç®—æ³•æ¯”è¾ƒçš„è¯¦ç»†ç¨‹åº¦ã€‚</p>
<h3 id="ä¸€ä¸ªåŸåˆ™"><a href="#ä¸€ä¸ªåŸåˆ™" class="headerlink" title="ä¸€ä¸ªåŸåˆ™"></a>ä¸€ä¸ªåŸåˆ™</h3></li>
<li><p>æœ€é‡è¦çš„åŸåˆ™ï¼š<strong>Big Ohç¬¦å·</strong>å’Œ<strong>æœ€åæƒ…å†µåˆ†æ</strong>æ˜¯æå¤§ç®€åŒ–æˆ‘ä»¬æ¯”è¾ƒç®—æ³•æ•ˆç‡çš„åŠŸèƒ½çš„å·¥å…·ã€‚</p>
</li>
<li><p>å¤§Oçš„é€šä¿—è§£æ³•ï¼šæ‰¾ä¸€ä¸ªcï¼Œä¸ç®¡næ€ä¹ˆå˜å¤§ï¼Œ$g(n)$éƒ½æ˜¯å…¶ä¸Šç•Œã€‚æ³¨æ„ï¼Œ$g(n)$æ˜¯æ¯”è¾ƒå¤§çš„é‚£ä¸€ä¸ª</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="ä¸Šä¸€é¡µ"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          æ–‡ç« ç›®å½•
        </li>
        <li class="sidebar-nav-overview">
          ç«™ç‚¹æ¦‚è§ˆ
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">è‘£é›„</p>
  <div class="site-description" itemprop="description">Learning in Harbin Institute of Technology</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">æ—¥å¿—</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">åˆ†ç±»</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">æ ‡ç­¾</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">è‘£é›„</span>
</div>
  <div class="powered-by">ç”± <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> å¼ºåŠ›é©±åŠ¨
  </div>

        


  <div style="display: none;">
    <script src="//s95.cnzz.com/z_stat.php?id=1278837449&web_id=1278837449"></script>
  </div>






      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 't8n8RTilca5Gm0vKToaMrjRU-gzGzoHsz',
      appKey     : 'x4Jty8MrDpczjPANtbbGhwXX',
      placeholder: "è¯·ç•™ä¸‹ä¸€ç‚¹ç—•è¿¹å§, è¯„è®ºå°†æ°¸è¿œç•™å­˜",
      avatar     : 'robohash',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
